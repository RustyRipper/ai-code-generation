{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Znakowanie i identyfikacja kodu wygenerowanego przez AI\n",
    "\n",
    "Temat automatycznej generacji kodu źródłowego przez Sztuczną Inteliencję (AI) jest obszerny i obejmuje różne techniki, modele oraz zastosowania. Przedmiotem naszego zainteresowania na kursie jest natomiast znalezienie sposobu na zrozumienie czy popularne generatory kodu (i ogólnego użycia) tworzą go w specyficzny dla siebie sposób, i jak tak to jaki. Chcemy odpowiedzieć na pytanie czy w dostarczonym kodzie można odnaleźć pewne statystyczne wzorce - czyli, czy AI posiada swój styl mogący go później zidentyfikować jako autora - podobnie do programistów.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naszą pierwszą czynnością było wygenerowanie kilku prostych matematycznych funkcji i algorytmów w języku Python przy użyciu ChatGPT. Już na pierwszy rzut okna dało się zauważyć pewne elementy, które mogłyby odbiegać od *normy*:\n",
    "- kod nie korzysta możliwości Pythona co do pisania zwięzłych i bardziej złożonych struktur syntaktycznych\n",
    "- przy każdej operacji pojawia się komentarz zaczynający się od wielkiej litery, a zmienne wykorzystywane mają dokładnie taką nazwę jak w komentarzu\n",
    "\n",
    "Celem jest znalezienie **statystycznego** potwierdzenia naszej intuicji, oraz znalezienie **ukrytych artefaktów** o ile istnieją - za pomocą różnych metod i narzędzie programistycznych.\n",
    "\n",
    "Zadanie detekcji, czy dany fragement kodu został napisany przez AI okazał się niezbyt dobrze opisanym w literaturze tematem, a przynajmniej takie odnieślismy wrażenie. Większość artykułów dotyczyło danych w postaci **tekstowej**. Kod oczywiście również jest zapisany w postaci tekstowej, jednak języki programowania ze względu na swoje przeznaczenie różnią się w aspektach gramatycznych i składniowych, które potrafiły być czynnikiem decydującym o decyzji czy badany tekst jest dziełem człowieka czy AI.\n",
    "Wyżej wymienione przypuszczenia przykuły też uwagę innych badaczy [1](https://arxiv.org/abs/2405.16133), którzy również zwrócili uwagę na dysproporcję w dokumentacji wykrywania wygenerowanych przez AI fragmentów kodu a tekstu i niedostępności datasetów - co było trochę oczekiwane, ponieważ dopiero od w miare niedługiego okresu, rozwiązania AI stały się użytecznym narzędziem a zarazem problemem.\n",
    "\n",
    "W swoim artykule zaprezentowali metodę wykrywania polegającą na porównaniu przepisywania przez AI kodu przygotowanego przez 1. człowieka i 2. ai. \n",
    "\n",
    "![llm rewriting](./assets/llmrewriting.png)",
    "\n",
    "Dzięki tej obserwacji przygotowali dataset z sztucznie wygenerowanymi funkcjami, z którego możemy skorzystać. Jednak zdecydowali się nauczyć model, a my chcemy deterministycznie znaleźć te różnice.\n",
    "\n",
    "W innym znalezionym badaniu [2] [https://ieeexplore.ieee.org/document/9674263/], badacze zdecydowali się stworzyć algorytm heurystyczny, który uwzględniał analizę programów z repozytoriów.\n",
    "\n",
    "![heurystyka](./assets/heurystyka.png)",
    "\n",
    "Na jego podobieństwo zbudowaliśmy własny algorytm heurystyczny, który mimo swojej prostoty i małej próbki danych potrafił wskazać na pochodzenie syntetyczne lub nie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Analysis for code_samples/ai/binary_search.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/bubble_sort.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/factorial.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/fib.py ===\n",
      "'AI Generated Probability (%): 88.89\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/is_prime.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/palindrome.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/binary_search.py ===\n",
      "'AI Generated Probability (%): 66.67\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/bubble_sort.py ===\n",
      "'AI Generated Probability (%): 44.44\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/factorial.py ===\n",
      "'AI Generated Probability (%): 33.33\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/fib.py ===\n",
      "'AI Generated Probability (%): 44.44\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/is_prime.py ===\n",
      "'AI Generated Probability (%): 44.44\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/palindrome.py ===\n",
      "'AI Generated Probability (%): 33.33\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def analyze_code(code, filename):\n",
    "    results = {\"Filename\": filename}\n",
    "\n",
    "    # Keyword Distribution\n",
    "    keywords = ['if', 'else', 'for', 'while', 'def', 'class', 'try', 'except']\n",
    "    keyword_distribution = {kw: len(re.findall(r'\\b' + kw + r'\\b', code)) for kw in keywords}\n",
    "    results[\"Keyword Distribution\"] = keyword_distribution\n",
    "\n",
    "    # Naming Conventions\n",
    "    pascal_case = len(re.findall(r'\\b[A-Z][a-z]*[A-Z][a-z]*\\b', code))\n",
    "    snake_case = len(re.findall(r'\\b[a-z]+(_[a-z]+)+\\b', code))\n",
    "    results[\"Naming Conventions\"] = {\"PascalCase\": pascal_case, \"snake_case\": snake_case}\n",
    " \n",
    "    # Comment Analysis\n",
    "    comments = re.findall(r'#.*', code)\n",
    "    average_comment_length = sum(len(comment) for comment in comments) / len(comments) if comments else 0\n",
    "    overly_detailed_comments = sum(1 for comment in comments if len(comment) > 40)\n",
    "    results[\"Comments\"] = {\n",
    "        \"Total Comments\": len(comments),\n",
    "        \"Average Length\": average_comment_length,\n",
    "        \"Overly Detailed Comments\": overly_detailed_comments\n",
    "    }\n",
    "\n",
    "    # Cyclomatic Complexity\n",
    "    tree = ast.parse(code)\n",
    "    complexity = 1\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, (ast.If, ast.For, ast.While, ast.Try, ast.FunctionDef)):\n",
    "            complexity += 1\n",
    "    results[\"Cyclomatic Complexity\"] = complexity\n",
    "\n",
    "    # Code Duplication Detection\n",
    "    def find_duplicate_functions(tree):\n",
    "        function_names = defaultdict(list)\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.FunctionDef):\n",
    "                function_names[node.name].append(ast.get_source_segment(code, node))\n",
    "\n",
    "        duplicates = {name: func_code for name, func_code in function_names.items() if len(func_code) > 1}\n",
    "        return duplicates\n",
    "\n",
    "    duplicates = find_duplicate_functions(tree)\n",
    "    results[\"Duplicate Functions\"] = {name: len(funcs) for name, funcs in duplicates.items()}\n",
    "\n",
    "    # Repetitive Patterns Check\n",
    "    repetitive_patterns = re.findall(r'\\b\\w+\\b', code)\n",
    "    repetitive_count = len([word for word in repetitive_patterns if repetitive_patterns.count(word) > 3])\n",
    "    results[\"Repetitive Patterns\"] = repetitive_count\n",
    "\n",
    "    # Variable & Function Naming Analysis\n",
    "    overly_descriptive_names = sum(\n",
    "        1 for name in re.findall(r'\\b[a-zA-Z_]{10,}\\b', code) if '_' in name\n",
    "    )\n",
    "    results[\"Overly Descriptive Names\"] = overly_descriptive_names\n",
    "\n",
    "    # Simple Logic and Default Values\n",
    "    default_values = len(re.findall(r'\\b=\\s*[\\'\\\"\\d\\[\\]\\{\\}\\(\\)]', code))\n",
    "    results[\"Default Values\"] = default_values\n",
    "\n",
    "    # Exception Handling\n",
    "    exception_handlers = len(re.findall(r'\\btry\\b.*?\\bexcept\\b', code, re.DOTALL))\n",
    "    results[\"Exception Handling\"] = exception_handlers\n",
    "\n",
    "    # AI Generated Probability\n",
    "    ai_score = 0\n",
    "    total_weight = 9\n",
    "\n",
    "    ai_score += (complexity < 10) * (1 / total_weight)\n",
    "    ai_score += (average_comment_length > 15) * (2 / total_weight)\n",
    "    ai_score += (pascal_case == 0) * (1 / total_weight)\n",
    "    ai_score += (snake_case > 0) * (1 / total_weight)\n",
    "    ai_score += (len(duplicates) > 0) * (0.5 / total_weight)\n",
    "    ai_score += (repetitive_count > 5) * (1 / total_weight)\n",
    "    ai_score += (overly_descriptive_names > 2) * (1 / total_weight)\n",
    "    ai_score += (default_values > 2) * (0.5 / total_weight)\n",
    "    ai_score += (exception_handlers <= 2) * (1 / total_weight)\n",
    "\n",
    "    ai_probability = ai_score * 100\n",
    "    results[\"AI Generated Probability (%)\"] = round(ai_probability, 2)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def analyze_directory(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".py\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, 'r') as file:\n",
    "                code = file.read()\n",
    "                results = analyze_code(code, filename)\n",
    "\n",
    "                print(f\"=== Analysis for {directory}/{filename} ===\")\n",
    "                # for key, value in results.items():\n",
    "                #     print(f\"{key}: {value}\")\n",
    "                print(f\"'AI Generated Probability (%): {results['AI Generated Probability (%)']}\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "\n",
    "analyze_directory('code_samples/ai')\n",
    "analyze_directory('code_samples/human')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obliczone prawdopodobieństwo przyjmuje zauważalnie wyższe wartości dla syntetycznych kodów. \n",
    "\n",
    "---\n",
    "\n",
    "Kolejnym etapem jest skupienie się na sposobie zakodowania kodu - spróbowaliśmy zawrzeć wzorzec do kodu. Mianowicie, dla wybranego tekstu kodu, w co drugiej linijce dodajemy spację lub tabulator do końca linii. Te znaki będą nam mówić o wartości bitu. \n",
    "- spacja = 0\n",
    "- tab = 1\n",
    "\n",
    "Znaki są ustawiane w taki sposób, aby odczytując kod z góry do dołu tworzyły nam się bloki bajtowe, które są kodem litery naszego hasła.\n",
    "Limitacją na razie jest długość kodu i długość hasła, ale to będzie ulepszane. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "b'# ai_binary_search.py\\n'\n",
      "00100011\n",
      "--------------------------\n",
      "FILE LINE IN BYTES: b'# ai_binary_search.py\\n'\n",
      "FILE LINE IN BYTES: b'\\n'\n",
      "FILE LINE IN BYTES: b'def binary_search(arr, target):\\n'\n",
      "FILE LINE IN BYTES: b'    \"\"\"\\n'\n",
      "FILE LINE IN BYTES: b'    Perform a binary search on a sorted list to find the index of a target value.\\n'\n",
      "FILE LINE IN BYTES: b'\\n'\n",
      "FILE LINE IN BYTES: b'    Parameters:\\n'\n",
      "FILE LINE IN BYTES: b'    arr (list): The sorted list of elements to search.\\n'\n",
      "FILE LINE IN BYTES: b'    target (int): The value to search for in the list.\\n'\n",
      "FILE LINE IN BYTES: b'\\n'\n",
      "FILE LINE IN BYTES: b'    Returns:\\n'\n",
      "FILE LINE IN BYTES: b'    int: The index of the target in the list, or -1 if the target is not found.\\n'\n",
      "FILE LINE IN BYTES: b'    \"\"\"\\n'\n",
      "FILE LINE IN BYTES: b'    left = 0\\n'\n",
      "FILE LINE IN BYTES: b'    right = len(arr) - 1\\n'\n",
      "FILE LINE IN BYTES: b'\\n'\n",
      "FILE LINE IN BYTES: b'    # Loop until the left index exceeds the right index\\n'\n",
      "FILE LINE IN BYTES: b'    while left <= right:\\n'\n",
      "FILE LINE IN BYTES: b'        middle = (left + right) // 2\\n'\n",
      "FILE LINE IN BYTES: b'        if arr[middle] == target:\\n'\n",
      "FILE LINE IN BYTES: b'            return middle\\n'\n",
      "FILE LINE IN BYTES: b'        elif arr[middle] < target:\\n'\n",
      "FILE LINE IN BYTES: b'            left = middle + 1\\n'\n",
      "FILE LINE IN BYTES: b'        else:\\n'\n",
      "FILE LINE IN BYTES: b'            right = middle - 1\\n'\n",
      "FILE LINE IN BYTES: b'\\n'\n",
      "FILE LINE IN BYTES: b'    return -1\\n'\n",
      "UNUSUAL CHARACTERS:  [(0, 35), (0, 32), (0, 46), (0, 10), (1, 10), (2, 32), (2, 40), (2, 44), (2, 32), (2, 41), (2, 58), (2, 10), (3, 32), (3, 32), (3, 32), (3, 32), (3, 34), (3, 34), (3, 34), (3, 10), (4, 32), (4, 32), (4, 32), (4, 32), (4, 32), (4, 32), (4, 32), (4, 32), (4, 32), (4, 32), (4, 32), (4, 32), (4, 32), (4, 32), (4, 32), (4, 32), (4, 32), (4, 32), (4, 32), (4, 46), (4, 10), (5, 10), (6, 32), (6, 32), (6, 32), (6, 32), (6, 58), (6, 10), (7, 32), (7, 32), (7, 32), (7, 32), (7, 32), (7, 40), (7, 41), (7, 58), (7, 32), (7, 32), (7, 32), (7, 32), (7, 32), (7, 32), (7, 32), (7, 46), (7, 10), (8, 32), (8, 32), (8, 32), (8, 32), (8, 32), (8, 40), (8, 41), (8, 58), (8, 32), (8, 32), (8, 32), (8, 32), (8, 32), (8, 32), (8, 32), (8, 32), (8, 46), (8, 10), (9, 10), (10, 32), (10, 32), (10, 32), (10, 32), (10, 58), (10, 10), (11, 32), (11, 32), (11, 32), (11, 32), (11, 58), (11, 32), (11, 32), (11, 32), (11, 32), (11, 32), (11, 32), (11, 32), (11, 32), (11, 44), (11, 32), (11, 32), (11, 45), (11, 32), (11, 32), (11, 32), (11, 32), (11, 32), (11, 32), (11, 46), (11, 10), (12, 32), (12, 32), (12, 32), (12, 32), (12, 34), (12, 34), (12, 34), (12, 10), (13, 32), (13, 32), (13, 32), (13, 32), (13, 32), (13, 61), (13, 32), (13, 10), (14, 32), (14, 32), (14, 32), (14, 32), (14, 32), (14, 61), (14, 32), (14, 40), (14, 41), (14, 32), (14, 45), (14, 32), (14, 10), (15, 10), (16, 32), (16, 32), (16, 32), (16, 32), (16, 35), (16, 32), (16, 32), (16, 32), (16, 32), (16, 32), (16, 32), (16, 32), (16, 32), (16, 32), (16, 10), (17, 32), (17, 32), (17, 32), (17, 32), (17, 32), (17, 32), (17, 60), (17, 61), (17, 32), (17, 58), (17, 10), (18, 32), (18, 32), (18, 32), (18, 32), (18, 32), (18, 32), (18, 32), (18, 32), (18, 32), (18, 61), (18, 32), (18, 40), (18, 32), (18, 43), (18, 32), (18, 41), (18, 32), (18, 47), (18, 47), (18, 32), (18, 10), (19, 32), (19, 32), (19, 32), (19, 32), (19, 32), (19, 32), (19, 32), (19, 32), (19, 32), (19, 32), (19, 61), (19, 61), (19, 32), (19, 58), (19, 10), (20, 32), (20, 32), (20, 32), (20, 32), (20, 32), (20, 32), (20, 32), (20, 32), (20, 32), (20, 32), (20, 32), (20, 32), (20, 32), (20, 10), (21, 32), (21, 32), (21, 32), (21, 32), (21, 32), (21, 32), (21, 32), (21, 32), (21, 32), (21, 32), (21, 60), (21, 32), (21, 58), (21, 10), (22, 32), (22, 32), (22, 32), (22, 32), (22, 32), (22, 32), (22, 32), (22, 32), (22, 32), (22, 32), (22, 32), (22, 32), (22, 32), (22, 61), (22, 32), (22, 32), (22, 43), (22, 32), (22, 10), (23, 32), (23, 32), (23, 32), (23, 32), (23, 32), (23, 32), (23, 32), (23, 32), (23, 58), (23, 10), (24, 32), (24, 32), (24, 32), (24, 32), (24, 32), (24, 32), (24, 32), (24, 32), (24, 32), (24, 32), (24, 32), (24, 32), (24, 32), (24, 61), (24, 32), (24, 32), (24, 45), (24, 32), (24, 10), (25, 10), (26, 32), (26, 32), (26, 32), (26, 32), (26, 32), (26, 45), (26, 10)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmsg = \"abc def\"\\narr = bytes(msg, \\'utf-8\\')\\nprint(arr)\\n\\ntext = \"aąbc def\"\\nta = text.encode(\\'utf-8\\')\\nprint(ta)\\nprint(ta[0])\\nprint(ta[1])\\nprint(ta[2])\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' NA RAZIE NIE\n",
    "example_ai = 'code_samples/ai/binary_search.py'\n",
    "with open(example_ai, 'rb') as f:\n",
    "    content_string = f.readlines()\n",
    "\n",
    "print(content_string[0][0])\n",
    "print(content_string[0])\n",
    "print(format(content_string[0][0], '08b'))\n",
    "print('--------------------------')\n",
    "\n",
    "latin_chars_and_nrs = [(65, 122), (48, 57)]\n",
    "\n",
    "def check_for_unusual_chars(file_bytelines: list):\n",
    "    unusual_chars = []\n",
    "    for i, line in enumerate(file_bytelines):\n",
    "        print(\"FILE LINE IN BYTES:\", line)\n",
    "        for char_nr in line:\n",
    "            if not any(usual[0] <= char_nr <= usual[1] for usual in latin_chars_and_nrs):\n",
    "                unusual_chars.append((i, char_nr))\n",
    "    return unusual_chars\n",
    "\n",
    "\n",
    "unusual_chars = check_for_unusual_chars(content_string)\n",
    "print(\"UNUSUAL CHARACTERS: \", unusual_chars)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

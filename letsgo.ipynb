{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Znakowanie i identyfikacja kodu wygenerowanego przez AI\n",
    "\n",
    "Temat automatycznej generacji kodu źródłowego przez Sztuczną Inteliencję (AI) jest obszerny i obejmuje różne techniki, modele oraz zastosowania. Przedmiotem naszego zainteresowania na kursie jest natomiast znalezienie sposobu na zrozumienie czy popularne generatory kodu (i ogólnego użycia) tworzą go w specyficzny dla siebie sposób, i jak tak to jaki. Chcemy odpowiedzieć na pytanie czy w dostarczonym kodzie można odnaleźć pewne statystyczne wzorce - czyli, czy AI posiada swój styl mogący go później zidentyfikować jako autora - podobnie do programistów.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naszą pierwszą czynnością było wygenerowanie kilku prostych matematycznych funkcji i algorytmów w języku Python przy użyciu ChatGPT. Już na pierwszy rzut okna dało się zauważyć pewne elementy, które mogłyby odbiegać od *normy*:\n",
    "- kod nie korzysta możliwości Pythona co do pisania zwięzłych i bardziej złożonych struktur syntaktycznych\n",
    "- przy każdej operacji pojawia się komentarz zaczynający się od wielkiej litery, a zmienne wykorzystywane mają dokładnie taką nazwę jak w komentarzu\n",
    "\n",
    "Celem jest znalezienie **statystycznego** potwierdzenia naszej intuicji, oraz znalezienie **ukrytych artefaktów** o ile istnieją - za pomocą różnych metod i narzędzie programistycznych.\n",
    "\n",
    "Zadanie detekcji, czy dany fragement kodu został napisany przez AI okazał się niezbyt dobrze opisanym w literaturze tematem, a przynajmniej takie odnieślismy wrażenie. Większość artykułów dotyczyło danych w postaci **tekstowej**. Kod oczywiście również jest zapisany w postaci tekstowej, jednak języki programowania ze względu na swoje przeznaczenie różnią się w aspektach gramatycznych i składniowych, które potrafiły być czynnikiem decydującym o decyzji czy badany tekst jest dziełem człowieka czy AI.\n",
    "Wyżej wymienione przypuszczenia przykuły też uwagę innych badaczy [1](https://arxiv.org/abs/2405.16133), którzy również zwrócili uwagę na dysproporcję w dokumentacji wykrywania wygenerowanych przez AI fragmentów kodu a tekstu i niedostępności datasetów - co było trochę oczekiwane, ponieważ dopiero od w miare niedługiego okresu, rozwiązania AI stały się użytecznym narzędziem a zarazem problemem.\n",
    "\n",
    "W swoim artykule zaprezentowali metodę wykrywania polegającą na porównaniu przepisywania przez AI kodu przygotowanego przez 1. człowieka i 2. ai. \n",
    "\n",
    "![llm rewriting](./assets/llmrewriting.png)\n",
    "\n",
    "Dzięki tej obserwacji przygotowali dataset z sztucznie wygenerowanymi funkcjami, z którego możemy skorzystać. Jednak zdecydowali się nauczyć model, a my chcemy **deterministycznie** znaleźć te różnice.\n",
    "\n",
    "W innym znalezionym badaniu [2](https://ieeexplore.ieee.org/document/9674263/), badacze zdecydowali się stworzyć algorytm heurystyczny, który uwzględniał analizę programów z repozytoriów.\n",
    "\n",
    "![heurystyka](./assets/heurystyka.png)\n",
    "\n",
    "Na jego podobieństwo zbudowaliśmy własny algorytm heurystyczny, który mimo swojej prostoty i małej próbki danych potrafił wskazać na pochodzenie syntetyczne lub nie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Analysis for code_samples/ai/binary_search.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/bubble_sort.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/factorial.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/fib.py ===\n",
      "'AI Generated Probability (%): 88.89\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/is_prime.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/palindrome.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "=== Analysis for code_samples/human/binary_search.py ===\n",
      "'AI Generated Probability (%): 66.67\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/bubble_sort.py ===\n",
      "'AI Generated Probability (%): 44.44\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/factorial.py ===\n",
      "'AI Generated Probability (%): 33.33\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/fib.py ===\n",
      "'AI Generated Probability (%): 44.44\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/is_prime.py ===\n",
      "'AI Generated Probability (%): 44.44\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/palindrome.py ===\n",
      "'AI Generated Probability (%): 33.33\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def analyze_code_heuristic(code, filename):\n",
    "    results = {\"Filename\": filename}\n",
    "\n",
    "    # Keyword Distribution\n",
    "    keywords = ['if', 'else', 'for', 'while', 'def', 'class', 'try', 'except']\n",
    "    keyword_distribution = {kw: len(re.findall(r'\\b' + kw + r'\\b', code)) for kw in keywords}\n",
    "    results[\"Keyword Distribution\"] = keyword_distribution\n",
    "\n",
    "    # Naming Conventions\n",
    "    pascal_case = len(re.findall(r'\\b[A-Z][a-z]*[A-Z][a-z]*\\b', code))\n",
    "    snake_case = len(re.findall(r'\\b[a-z]+(_[a-z]+)+\\b', code))\n",
    "    results[\"Naming Conventions\"] = {\"PascalCase\": pascal_case, \"snake_case\": snake_case}\n",
    " \n",
    "    # Comment Analysis\n",
    "    comments = re.findall(r'#.*', code)\n",
    "    average_comment_length = sum(len(comment) for comment in comments) / len(comments) if comments else 0\n",
    "    overly_detailed_comments = sum(1 for comment in comments if len(comment) > 40)\n",
    "    results[\"Comments\"] = {\n",
    "        \"Total Comments\": len(comments),\n",
    "        \"Average Length\": average_comment_length,\n",
    "        \"Overly Detailed Comments\": overly_detailed_comments\n",
    "    }\n",
    "\n",
    "    # Cyclomatic Complexity\n",
    "    tree = ast.parse(code)\n",
    "    complexity = 1\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, (ast.If, ast.For, ast.While, ast.Try, ast.FunctionDef)):\n",
    "            complexity += 1\n",
    "    results[\"Cyclomatic Complexity\"] = complexity\n",
    "\n",
    "    # Code Duplication Detection\n",
    "    def find_duplicate_functions(tree):\n",
    "        function_names = defaultdict(list)\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.FunctionDef):\n",
    "                function_names[node.name].append(ast.get_source_segment(code, node))\n",
    "\n",
    "        duplicates = {name: func_code for name, func_code in function_names.items() if len(func_code) > 1}\n",
    "        return duplicates\n",
    "\n",
    "    duplicates = find_duplicate_functions(tree)\n",
    "    results[\"Duplicate Functions\"] = {name: len(funcs) for name, funcs in duplicates.items()}\n",
    "\n",
    "    # Repetitive Patterns Check\n",
    "    repetitive_patterns = re.findall(r'\\b\\w+\\b', code)\n",
    "    repetitive_count = len([word for word in repetitive_patterns if repetitive_patterns.count(word) > 3])\n",
    "    results[\"Repetitive Patterns\"] = repetitive_count\n",
    "\n",
    "    # Variable & Function Naming Analysis\n",
    "    overly_descriptive_names = sum(\n",
    "        1 for name in re.findall(r'\\b[a-zA-Z_]{10,}\\b', code) if '_' in name\n",
    "    )\n",
    "    results[\"Overly Descriptive Names\"] = overly_descriptive_names\n",
    "\n",
    "    # Simple Logic and Default Values\n",
    "    default_values = len(re.findall(r'\\b=\\s*[\\'\\\"\\d\\[\\]\\{\\}\\(\\)]', code))\n",
    "    results[\"Default Values\"] = default_values\n",
    "\n",
    "    # Exception Handling\n",
    "    exception_handlers = len(re.findall(r'\\btry\\b.*?\\bexcept\\b', code, re.DOTALL))\n",
    "    results[\"Exception Handling\"] = exception_handlers\n",
    "\n",
    "    # AI Generated Probability\n",
    "    ai_score = 0\n",
    "    total_weight = 9\n",
    "\n",
    "    ai_score += (complexity < 10) * (1 / total_weight)\n",
    "    ai_score += (average_comment_length > 15) * (2 / total_weight)\n",
    "    ai_score += (pascal_case == 0) * (1 / total_weight)\n",
    "    ai_score += (snake_case > 0) * (1 / total_weight)\n",
    "    ai_score += (len(duplicates) > 0) * (0.5 / total_weight)\n",
    "    ai_score += (repetitive_count > 5) * (1 / total_weight)\n",
    "    ai_score += (overly_descriptive_names > 2) * (1 / total_weight)\n",
    "    ai_score += (default_values > 2) * (0.5 / total_weight)\n",
    "    ai_score += (exception_handlers <= 2) * (1 / total_weight)\n",
    "\n",
    "    ai_probability = ai_score * 100\n",
    "    results[\"AI Generated Probability (%)\"] = round(ai_probability, 2)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def analyze_directory(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".py\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, 'r') as file:\n",
    "                code = file.read()\n",
    "                results = analyze_code_heuristic(code, filename)\n",
    "\n",
    "                print(f\"=== Analysis for {directory}/{filename} ===\")\n",
    "                # for key, value in results.items():\n",
    "                #     print(f\"{key}: {value}\")\n",
    "                print(f\"'AI Generated Probability (%): {results['AI Generated Probability (%)']}\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "\n",
    "analyze_directory('code_samples/ai')\n",
    "print(\"========================\\n\")\n",
    "analyze_directory('code_samples/human')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla przygotowanych - małolicznych próbek, obliczone prawdopodobieństwa przyjmują zauważalnie wyższe wartości dla syntetycznych kodów\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Znakowanie kodu\n",
    "\n",
    "W trakcie zajęć lekko zmodyfikowano temat projektu, mianowicie odeszliśmy od zagadnienia wygenerowanych kodów, na rzecz znakowania **naszego** kodu. Celem jest teraz poszukiwanie i implementacja znanych metod do watermarkingu, by można było przekazać kod funkcji markującej a następnie dało się potwierdzić istnienie nałożonych przez nas wzorów.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Niewidzialne znaki końca linii SPACE 0, TAB 1\n",
    "\n",
    "Kolejnym etapem jest skupienie się na sposobie zakodowania kodu - spróbowaliśmy zawrzeć wzorzec do kodu. Mianowicie, dla wybranego tekstu kodu, w co drugiej linijce dodajemy spację lub tabulator do końca linii. Te znaki będą nam mówić o wartości bitu. \n",
    "- spacja = 0\n",
    "- tab = 1\n",
    "\n",
    "Znaki są ustawiane w taki sposób, aby odczytując kod z góry do dołu tworzyły nam się bloki bajtowe, które są kodem litery naszego hasła.\n",
    "Limitacją na razie jest długość kodu i długość hasła, ale to będzie ulepszane. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watermark ['L', 'A', 'B', 'O', 'R', 'A', 'T', 'O', 'R', 'I', 'A']\n",
      "Watermark binary: 01001100x01000001x01000010x01001111x01010010x01000001x01010100x01001111x01010010x01001001x01000001\n",
      "Dlugosc watermarku: 11\n",
      "Dlugosc binarna watermarku: 88\n",
      "\n",
      "BINARY PATTERN ['0', '1', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '1', '0', '1', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '1', '0', '1', '0', '1', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '1', '0', '1', '0', '0', '1', '0', '0', '1', '0', '0', '1', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '1']\n",
      "Znaleziony kod: LABORATORIALAB\n"
     ]
    }
   ],
   "source": [
    "def add_watermark_space_tab(code, watermark=\"LABORATORIA\"):\n",
    "    \n",
    "    watermark_space_tab_list = ['\\t' if bit == '1' else ' ' for bit in ''.join(format(ord(c), '08b') for c in watermark)]\n",
    "    watermark_binary = 'x'.join([ format(ord(c), '08b') for c in watermark])\n",
    "    watermark_list = list(watermark)\n",
    "    \n",
    "    print(\"Watermark\", watermark_list)\n",
    "    print(\"Watermark binary:\", watermark_binary)\n",
    "    #print(\"Watermark char list:\", watermark_space_tab_list)\n",
    "    print('Dlugosc watermarku: ' + str(len(watermark)))\n",
    "    print('Dlugosc binarna watermarku: ' + str(len(watermark_space_tab_list)))\n",
    "    print()\n",
    "    \n",
    "    lines = code.splitlines()\n",
    "    \n",
    "    \n",
    "    # -------------------\n",
    "    # code length aware\n",
    "    \n",
    "    # every 2 lines, so scope is n*len(watermark_space_tab_list)\n",
    "    n = 2\n",
    "    \n",
    "    if len(lines) > n * len(watermark_space_tab_list):\n",
    "        \n",
    "        needed_bites = len(lines) // n\n",
    "        current_bites = len(watermark_space_tab_list)\n",
    "        \n",
    "        bites_to_add = needed_bites - current_bites\n",
    "        \n",
    "        # ile liter potrzebnych\n",
    "        m = bites_to_add // 8\n",
    "        # litery + 1 by nie bawić się w części\n",
    "        m = m + 1\n",
    "        \n",
    "        # ile tych liter do czesc watermarka\n",
    "        k = m // len(watermark_list)\n",
    "        r = m % len(watermark_list)\n",
    "        \n",
    "        watermark_list += k * watermark_list\n",
    "        watermark_list += watermark_list[:r]\n",
    "        \n",
    "        watermark_space_tab_list = ['\\t' if bit == '1' else ' ' for bit in ''.join(format(ord(c), '08b') for c in watermark_list)]\n",
    "        \n",
    "            \n",
    "    # -------------------\n",
    "    \n",
    "    for i in range(1, len(lines), n):\n",
    "        lines[i] += watermark_space_tab_list[i // n]\n",
    "            \n",
    "    \n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "\n",
    "def extract_watermark_space_tab(code):\n",
    "    lines = code.splitlines()\n",
    "\n",
    "    binary_pattern = []\n",
    "    for i in range(1, len(lines), 2):\n",
    "        if lines[i].endswith(\" \") or lines[i].endswith(\"\\t\"):\n",
    "            last_char = lines[i][-1]\n",
    "            binary_pattern.append('1' if last_char == '\\t' else '0')\n",
    "\n",
    "    print(\"BINARY PATTERN\", binary_pattern)\n",
    "    watermark_text = ''\n",
    "    for i in range(0, len(binary_pattern), 8):\n",
    "        byte = ''.join(binary_pattern[i:(i + 8)])\n",
    "        if len(byte) == 8:\n",
    "            watermark_text += chr(int(byte, 2))\n",
    "\n",
    "    return watermark_text if watermark_text else \"Brak znaku wodnego\"\n",
    "\n",
    "\n",
    "with open(\"init-code/init_long.py\", \"r\") as f:\n",
    "    code_example = f.read()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "watermarked_code = add_watermark_space_tab(code_example)\n",
    "#print(\"Zwatermarkowany kod:\\n\" + watermarked_code)\n",
    "\n",
    "detected_watermark = extract_watermark_space_tab(watermarked_code)\n",
    "print(\"Znaleziony kod:\", detected_watermark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Sortowanie importów\n",
    "\n",
    "Poniższy kod realizuje dodanie watermarka do sekcji importow w taki sposob ze sortuje je wedlug hash'a `sha256`. \\\n",
    "Widoczna jest również metoda która sprawdza czy zmieniony kod zawiera w sobie watermarka.\n",
    "\n",
    "Obserwujemy również wyniki:\n",
    "\n",
    "Czy kod zawiera watermark?\n",
    "True\n",
    "\n",
    "Czy oryginalny kod zawiera watermark?\n",
    "False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kod po dodaniu watermarku:\n",
      "\n",
      "from math import sqrt\n",
      "import os\n",
      "from itertools import permutations\n",
      "import sys\n",
      "from collections import defaultdict\n",
      "\n",
      "\n",
      "\n",
      "def example_function():\n",
      "    print(\"Hello, World!\")\n",
      "    return 42\n",
      "\n",
      "def calculate_square_root(x):\n",
      "    return sqrt(x)\n",
      "\n",
      "def list_permutations(iterable):\n",
      "    return list(permutations(iterable))\n",
      "    \n",
      "\n",
      "Czy kod zawiera watermark?\n",
      "True\n",
      "\n",
      "Czy oryginalny kod zawiera watermark?\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "def add_watermark_in_imports(code, watermark):\n",
    "    lines = code.splitlines()\n",
    "    \n",
    "    imports = [line for line in lines if line.startswith(\"import\") or line.startswith(\"from\")]\n",
    "    other_lines = [line for line in lines if not (line.startswith(\"import\") or line.startswith(\"from\"))]\n",
    "    \n",
    "    # hash\n",
    "    watermark_hash = hashlib.sha256(watermark.encode()).hexdigest()\n",
    "    # sort\n",
    "    sorted_imports = sorted(imports, key=lambda x: hashlib.sha256((x + watermark_hash).encode()).hexdigest())\n",
    "    return '\\n'.join(sorted_imports + other_lines)\n",
    "\n",
    "def is_watermarked_imports(code, watermark):\n",
    "    lines = code.splitlines()\n",
    "    \n",
    "    imports = [line for line in lines if line.startswith(\"import\") or line.startswith(\"from\")]\n",
    "    \n",
    "    watermark_hash = hashlib.sha256(watermark.encode()).hexdigest()\n",
    "    sorted_imports = sorted(imports, key=lambda x: hashlib.sha256((x + watermark_hash).encode()).hexdigest())\n",
    "    \n",
    "    return imports == sorted_imports\n",
    "\n",
    "\n",
    "example_code = \"\"\"\n",
    "\n",
    "import os\n",
    "from math import sqrt\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from itertools import permutations\n",
    "\n",
    "def example_function():\n",
    "    print(\"Hello, World!\")\n",
    "    return 42\n",
    "\n",
    "def calculate_square_root(x):\n",
    "    return sqrt(x)\n",
    "\n",
    "def list_permutations(iterable):\n",
    "    return list(permutations(iterable))\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "watermarked_code = add_watermark_in_imports(example_code, \"UniqueWatermark2024\")\n",
    "print(\"Kod po dodaniu watermarku:\\n\")\n",
    "print(watermarked_code)\n",
    "\n",
    "print(\"\\nCzy kod zawiera watermark?\")\n",
    "is_watermarked = is_watermarked_imports(watermarked_code, \"UniqueWatermark2024\")\n",
    "print(is_watermarked)\n",
    "\n",
    "print(\"\\nCzy oryginalny kod zawiera watermark?\")\n",
    "not_watermarked = is_watermarked_imports(example_code, \"UniqueWatermark2024\")\n",
    "print(not_watermarked)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Dodawanie *stylu*\n",
    "\n",
    "Poniższy kod realizuje zamiane znaków w ich podobne odpowiedniki np. `l -> 1` \\\n",
    "Kod pomija wbudowane nazwy oraz pomija pierwsze znaki po to, żeby możliwa była kompilacja zwatermarkowanego kodu. \\\n",
    "Przykładowa zmiana nazwy zmiennej `total -> tota1`. \\\n",
    "Dodatkowo dodana została funkcja sprawdzająca watermark.\n",
    "\n",
    "Przykładowy wynik:\n",
    "Czy kod zawiera watermark w zmiennych i parametrach?\n",
    "True\n",
    "\n",
    "Czy oryginalny kod zawiera watermark w zmiennych i parametrach?\n",
    "False\n",
    "\n",
    "Problemem może być brak estetyczności kodu, i wyraźną chęć przepisania bądź zmiany nazw zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kod po dodaniu watermarku z podobnymi znakami:\n",
      "\n",
      "\n",
      "\n",
      "def calcul@te_ar3a(length, width):\n",
      "    result = length * width\n",
      "    return result\n",
      "\n",
      "def greet_user(name):\n",
      "    greeting = f\"Hello, {name}!\"\n",
      "    print(greeting)\n",
      "\n",
      "def comput3_sum(number5):\n",
      "    total = 0\n",
      "    print(\"--\")\n",
      "    for num in number5:\n",
      "        total += num\n",
      "    print(total)\n",
      "    return total\n",
      "    \n",
      "\n",
      "Czy kod zawiera watermark w zmiennych i parametrach?\n",
      "True\n",
      "\n",
      "Czy oryginalny kod zawiera watermark w zmiennych i parametrach?\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import re\n",
    "import keyword\n",
    "\n",
    "SIMILAR_CHARS = {\n",
    "    'a': '@',\n",
    "    'e': '3',\n",
    "    'i': '1',\n",
    "    'o': '0',\n",
    "    'l': '1',\n",
    "    's': '5',\n",
    "    't': '7'\n",
    "}\n",
    "\n",
    "BUILTINS = dir(__builtins__)\n",
    "\n",
    "def add_watermark_in_variables_similar_chars(code, watermark):\n",
    "\n",
    "    # wsm to ten hash nie jest wykorzystywany skoro i jak dajemy len(watermark_hash) ()= 4) jako warunek sprawdzający można by dodać jakoś zmienić na idk // 1000 \n",
    "    watermark_hash = hashlib.sha256(watermark.encode()).hexdigest()[:4]\n",
    "    #print(\"W HASH:\", watermark_hash, type(watermark_hash))\n",
    "    #hash_n = int(watermark_hash[0])\n",
    "    hash_n = int(re.sub(r'\\D', '1', watermark_hash)[0])\n",
    "    \n",
    "    def modify_variable(name):\n",
    "        if name in keyword.kwlist or name in BUILTINS:\n",
    "            return name\n",
    "        \n",
    "        modified_name = name[0]\n",
    "        for i, char in enumerate(name[1:], 1):\n",
    "            if char.lower() in SIMILAR_CHARS and i % hash_n == 0:\n",
    "                modified_name += SIMILAR_CHARS[char.lower()]\n",
    "            else:\n",
    "                modified_name += char\n",
    "        return modified_name\n",
    "\n",
    "    variable_pattern = re.compile(r'\\b([a-zA-Z_][a-zA-Z0-9_]*)\\b')\n",
    "    lines = code.splitlines()\n",
    "    updated_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        updated_line = variable_pattern.sub(\n",
    "            lambda match: modify_variable(match.group(1)), line)\n",
    "        \n",
    "        updated_lines.append(updated_line)\n",
    "    \n",
    "    return '\\n'.join(updated_lines)\n",
    "\n",
    "def is_watermarked_variables_similar_chars(code, watermark):\n",
    "\n",
    "    watermark_hash = hashlib.sha256(watermark.encode()).hexdigest()[:4]\n",
    "    #hash_n = int(watermark_hash[0])\n",
    "    hash_n = int(re.sub(r'\\D', '1', watermark_hash)[0])\n",
    "    \n",
    "    def check_variable(name):\n",
    "\n",
    "        original_name = name[0]\n",
    "        for i, char in enumerate(name[1:], 1):\n",
    "            if char in SIMILAR_CHARS.values() and i % hash_n == 0:\n",
    "                original_char = next((k for k, v in SIMILAR_CHARS.items() if v == char), None)\n",
    "                if original_char:\n",
    "                    original_name += original_char\n",
    "                else:\n",
    "                    return False\n",
    "            else:\n",
    "                original_name += char\n",
    "        \n",
    "        return original_name != name\n",
    "\n",
    "    variable_pattern = re.compile(r'\\b([a-zA-Z_][a-zA-Z0-9_]*)\\b')\n",
    "    for match in variable_pattern.findall(code):\n",
    "        if check_variable(match):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "example_code = \"\"\"\n",
    "\n",
    "def calculate_area(length, width):\n",
    "    result = length * width\n",
    "    return result\n",
    "\n",
    "def greet_user(name):\n",
    "    greeting = f\"Hello, {name}!\"\n",
    "    print(greeting)\n",
    "\n",
    "def compute_sum(numbers):\n",
    "    total = 0\n",
    "    print(\"--\")\n",
    "    for num in numbers:\n",
    "        total += num\n",
    "    print(total)\n",
    "    return total\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "watermark_vars = \"ImprovedWatermark2024x\"\n",
    "\n",
    "watermarked_code = add_watermark_in_variables_similar_chars(example_code, watermark_vars)\n",
    "print(\"Kod po dodaniu watermarku z podobnymi znakami:\\n\")\n",
    "print(watermarked_code)\n",
    "\n",
    "print(\"\\nCzy kod zawiera watermark w zmiennych i parametrach?\")\n",
    "is_watermarked = is_watermarked_variables_similar_chars(watermarked_code, watermark_vars)\n",
    "print(is_watermarked)\n",
    "\n",
    "print(\"\\nCzy oryginalny kod zawiera watermark w zmiennych i parametrach?\")\n",
    "not_watermarked = is_watermarked_variables_similar_chars(example_code, watermark_vars)\n",
    "print(not_watermarked)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Inne niewidzialne znaki\n",
    "\n",
    "Następnymi krokami, które chcieliśmy przetestować to:\n",
    "\n",
    "- dodawanie znaku NULL (char - 0) lub Zero-Width Space (utf-8 200B), do każdego stringu obecnego w kodzie. \n",
    "    \n",
    "\n",
    "- dodawanie zmiennej liczby znaków wybranych znaków do każdej linii, tak aby nawet po usunięciu kilku linijek, po odczytaniu liczby tych znaków można by spróbować statystycznie zweryfikować czy te dane pochodzą z wybranego przez nas rozkładu. Zapewne musiałby byc to rozkład normalny, ale z niezbyt dużą wartością średnią, żeby edytor kodu nie był w stanie wykryć *slidera*. Ale może gdyby dodawać znaku null to można by je dodawać z innego rozkładu - i to w kontekście każdej napotkanej funkcji, głównie wokół których zorganizowany jest kod. Takie sprawdzenie moglibyśmy zweryfikować m.in. szukając nadjdłuższego wspoólnego podciągu LCS...\n",
    "\n",
    "**JEDNAK EKSPERYMENTY Z INNYMI ZNAKAMI TEKSTU** nie działają jak zakładaliśmy, Python ma w tym elemencie surową politykę i dodane znaki na końcu linii powodują widoczne w popularnych ide zmiany, które dodatkowo  uniemożliwiają działanie kodu, więc zostają **PORZUCONE** na ten moment i zostajemy przy neutralnych `\" \"` i `\"\\t\"`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1: [0, 3, 1, 3, 3, 1, 2, 3, 0, 1, 2, 2, 0, 3, 3]\n",
      "P2: [0, 3, 1, 3, 3, 1, 2, 3, 0, 1, 2, 2, 0, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import hashlib\n",
    "import re\n",
    "    \n",
    "\n",
    "def add_multiple_inv_sign_watermark(code, watermark):\n",
    "\n",
    "    watermark_hash = hashlib.sha256(watermark.encode()).hexdigest()[:4]\n",
    "      \n",
    "    hash_n = int(re.sub(r'\\D', '1', watermark_hash))\n",
    "    random.seed(hash_n)\n",
    "    \n",
    "    pattern = []\n",
    "    lines = code.splitlines()\n",
    "    for i in range(len(lines)):\n",
    "        n = random.choice(range(4))\n",
    "        lines[i] += n * \" \"     \n",
    "        pattern.append(n)       \n",
    "\n",
    "    return '\\n'.join(lines), pattern\n",
    "\n",
    "\n",
    "'''\n",
    "def add_null_watermark(code):\n",
    "\n",
    "    lines = code.splitlines()\n",
    "    for i in range(len(lines)):\n",
    "        print(\"LEN LINE BEFORE:\", len(lines[i]))\n",
    "        lines[i] += random.choice(range(1,4))*chr(0)\n",
    "            \n",
    "        print(\"LEN LINES AFTER:\", len(lines[i]))\n",
    "        print(\"-\")\n",
    "\n",
    "    return ''.join(lines)\n",
    "\n",
    "def add_zws_watermark(code):\n",
    "\n",
    "    lines = code.splitlines()\n",
    "    for i in range(len(lines)):\n",
    "        print(\"LEN LINE BEFORE:\", len(lines[i]))\n",
    "        lines[i] += random.choice(range(1,4))*\"\\u200B\"\n",
    "            \n",
    "        print(\"LEN LINES AFTER:\", len(lines[i]))\n",
    "        print(\"-\")\n",
    "\n",
    "    return ''.join(lines)\n",
    "'''\n",
    "\n",
    "def extract_multiple_inv_signs_watermark(code):\n",
    "    \n",
    "    pattern = []\n",
    "    lines = code.splitlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        x = re.findall(r\" *$\", line)\n",
    "        pattern.append(len(x[0]))   \n",
    "         \n",
    "    return pattern\n",
    "\n",
    "    \n",
    "def get_func(filepath):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        code_example = f.read()\n",
    "\n",
    "    return code_example\n",
    "\n",
    "def save_func(filepath, code):\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(code)\n",
    "        \n",
    "    \n",
    "watermark_dist = \"ImprovedWatermark2024x\"\n",
    "   \n",
    "filename1 = \"./code_samples/human/is_prime.py\"\n",
    "filename2 = \"./watermarked_code/is_prime_w1.py\"\n",
    "\n",
    "code_watermarked = get_func(filename1)\n",
    "watermarked_code, original_pattern = add_multiple_inv_sign_watermark(code_watermarked, watermark_dist)\n",
    "    \n",
    "save_func(filename2, watermarked_code)\n",
    "\n",
    "print(\"P1:\", original_pattern)\n",
    "\n",
    "extracted_pattern = extract_multiple_inv_signs_watermark(watermarked_code)\n",
    "\n",
    "print(\"P2:\", extracted_pattern)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porównanie 2 uzyskanych wzorców:\n",
    "- użyty do zakodowania różnej informacji o spacjach, np. P1: [0, 3, 1, 3, 3, 1, 2, 3, 0, 1, 2, 2, 0, 3, 3]\n",
    "- odczytany z kodu, np. P2: [0, 3, 1, 3, 3, 1, 2, 3, 0, 1, 2, 2, 0, 3, 3]\n",
    "\n",
    "Przy użyciu tradycyjnego algorytmu będziemy chcieli je porównać również dla tekstu nie zmodyfikowanego przez użytkownika, który mógł usunąć pewną linijkę lub usunąc z niektórych spacje, kolejności raczej się nie zmienia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1: [0, 3, 1, 3, 3, 1, 2, 3, 0, 1, 2, 2, 0, 3, 3]\n",
      "P2: [0, 0, 0, 3, 1, 2, 3, 0, 2, 2, 0, 1]\n",
      "Prawdopodobieństwo ciągów: 0.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def LCS(s1, s2, m, n, memo):\n",
    " \n",
    "   # Base Case\n",
    "    if m == 0 or n == 0:\n",
    "        return 0\n",
    "\n",
    "    # Already exists in the memo table\n",
    "    if memo[m][n] != -1:\n",
    "        return memo[m][n]\n",
    "\n",
    "    # Match\n",
    "    if s1[m - 1] == s2[n - 1]:\n",
    "        memo[m][n] = 1 + LCS(s1, s2, m - 1, n - 1, memo)\n",
    "        return memo[m][n]\n",
    "\n",
    "    # Do not match\n",
    "    memo[m][n] = max(LCS(s1, s2, m, n - 1, memo),\n",
    "                     LCS(s1, s2, m - 1, n, memo))\n",
    "    \n",
    "    return memo[m][n]\n",
    "\n",
    "def check_patterns(pattern_list_original, pattern_list_extracted):\n",
    "    \n",
    "    original_pattern = list(map(lambda x: str(x), pattern_list_original))\n",
    "    extracted_pattern = list(map(lambda x: str(x), pattern_list_extracted ))\n",
    "\n",
    "    p1 = \"\".join(original_pattern)\n",
    "    p2 = \"\".join(extracted_pattern)\n",
    "    \n",
    "    m = len(p1)\n",
    "    n = len(p2)\n",
    "    memo = [[-1 for _ in range(n + 1)] for _ in range(m + 1)]\n",
    "    \n",
    "    p = LCS(p1, p2, m, n, memo)\n",
    "    \n",
    "    r =  p / len(original_pattern)\n",
    "    print(\"Prawdopodobieństwo ciągów:\", r)\n",
    "    \n",
    "    return r\n",
    "\n",
    "\n",
    "filename1 = \"./watermarked_code/is_prime_w1.py\"\n",
    "#modified, by removing lines and some spaces\n",
    "filename2 = \"./watermarked_code/is_prime_w2.py\" \n",
    "\n",
    "\n",
    "watermarked_code_unmodified = get_func(filename1)\n",
    "watermarked_code_modified = get_func(filename2)\n",
    "\n",
    "pattern1 = extract_multiple_inv_signs_watermark(watermarked_code_unmodified)\n",
    "pattern2 = extract_multiple_inv_signs_watermark(watermarked_code_modified)\n",
    "\n",
    "print(\"P1:\", pattern1)\n",
    "print(\"P2:\", pattern2)\n",
    "\n",
    "check_patterns(pattern1, pattern2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Inna, bardziej zaawansowana metoda steganografii\n",
    "\n",
    "Tym razem będziemy wzorować się na metodach zaprezentowanych w [3](https://arxiv.org/pdf/1302.2718). Metody, które chcielibyśmy przenieść na warunki programistyczne to:\n",
    "1. Dodawanie \"\\_\" do nazw zmiennych w odpowiednich miejscach, (zamiast zaproponowanych \"?\") ich rozmieszczenie w kodzie będzie możliwe do zakodowania pewnych informacji, ale możliwe że będzie wymagało to dodatkowej informacji, aby tak zmodyfikowane zmienne lub nazwy funkcji nie wzbudzały podejrzeń, szczegóły w referowanym pliku - metoda 1: **Missing Letter Puzzle**\n",
    "2. Nazywanie zmiennych w odpowiedni sposób - metoda 2: **Hiding Data in Wordlist**, tutaj ponownie, prawdopodobne, że wymagałoby to interwencji przez kodującego mając na uwadze pewne ściśle nałożone warunki.\n",
    "\n",
    "\n",
    "Oczywiście ze względu na strukturę kodu, wprowadzone modyfikacje do nazw musiałyby być uwzględnione globalnie a nie jedynie ad hoc. A raczej napewno wsm, bo będziemy musieli modyfikować długość zmiennej w trakcie algorytmu..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('left', 'leftzz_')\n",
      "('train_code', 'train_')\n",
      "('classification', 'classi_')\n",
      "('n', 'nm_ri_g')\n",
      "('generated_code', 'ge_erate')\n",
      "('capture_output', 'captu_')\n",
      "('train_labels', 'trai__la')\n",
      "('middle', 'mi_dl_g')\n",
      "('result', 're_ultcl')\n",
      "('right', 'rig_tpk')\n",
      "('model', 'model_')\n",
      "FLAG: 0\n",
      "SEEKING:\n",
      "MSG: LALIRAUIRIA\n",
      "CLOSE ENOUGH\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from regex import W\n",
    "# ~ Metoda 1: Missing Letter Puzzle: ? -> _, \n",
    "\n",
    "def missing_letter_puzzle():\n",
    "    return\n",
    "\n",
    "def retrieve_var_names(code, n):\n",
    "    \n",
    "    pattern = r'^\\s*([a-zA-Z_][a-zA-Z0-9_]*)\\s*='  # Dopasowuje nazwę zmiennej przed znakiem '='\n",
    "    initizalization_vars = set()\n",
    "    \n",
    "    lines = code.splitlines()\n",
    "    for i, line in enumerate(lines):\n",
    "\n",
    "        match = re.match(pattern, line)\n",
    "        if match:\n",
    "            #print(\"--\", match.group(1))\n",
    "            #print(\"M:\", match.group())\n",
    "            initizalization_vars.add(match.group(1))\n",
    "        \n",
    "        if len(initizalization_vars) == n:\n",
    "            break\n",
    "\n",
    "    \n",
    "    return list(initizalization_vars)\n",
    "\n",
    "\n",
    "def modify_word(word, des_length):\n",
    "    c_n = len(word)\n",
    "    d_n = des_length\n",
    "    m_word = \"\"\n",
    "    \n",
    "    change = {}\n",
    "    \n",
    "    if c_n == d_n:\n",
    "        m_word = word\n",
    "    elif c_n < d_n :\n",
    "        lets =  random.choices(\"abcdefghijklmnopqrstuwyz\", k=(d_n - c_n))\n",
    "        m_word = word + \"\".join(lets)\n",
    "    else:\n",
    "        m_word = word[:d_n]\n",
    "    \n",
    "    change[\"before\"] = word\n",
    "    change[\"after\"] = m_word\n",
    "\n",
    "    return change\n",
    "\n",
    "\n",
    "#SHOULD BE APPLIED TO 1 LIMITED SCOPE - FUNC, AND AT LEASTE len(KEYWORD) INITIALIZATIONS...\n",
    "\n",
    "def hide_mlp(init_vars, key):\n",
    "    ln = len(key)\n",
    "    flag = 0\n",
    "    changes = []\n",
    "    \n",
    "    for i, letter in enumerate(key):\n",
    "        \n",
    "        \n",
    "        n = ord(letter)\n",
    "        #print(\"N:\", n)\n",
    "        var = init_vars[i]\n",
    "        \n",
    "        if n < 100:\n",
    "            \n",
    "            flag = 0\n",
    "            q = n // 10\n",
    "            r = n % 10\n",
    "            \n",
    "            #print(\"-v\", var, \"-q\", q, '-r', r)\n",
    "            if q < 6:\n",
    "                l = 10 + q\n",
    "            else:\n",
    "                l = q\n",
    "            #print(\"l:\", l)\n",
    "            \n",
    "            word_change = modify_word(var, l)\n",
    "            word_before = word_change[\"before\"]\n",
    "            word_after = word_change[\"after\"]\n",
    "            #if word_before != word_after:\n",
    "            #    changes.append(word_change)            \n",
    "    \n",
    "            # x in the end is a equivalent to proposed 'hint'\n",
    "            if r == 0:\n",
    "                pos = np.random.choice(range(1, l))\n",
    "                word_after = word_after[:pos] + \"_\" + word_after[pos+1:] + \"x\"\n",
    "            elif r <= q:\n",
    "                word_after = word_after[:r] + \"_\" + word_after[r+1:]\n",
    "            else:\n",
    "                pos1 = r - q\n",
    "                if q in [6, 7, 8, 9]:\n",
    "                    pos2 = np.random.choice(range(3, l))\n",
    "                elif q in range(0, 6):\n",
    "                    pos2 = np.random.choice(range(9, l))\n",
    "                \n",
    "                if pos2 < pos1:\n",
    "                    pos2, pos1 = pos1, pos2\n",
    "                \n",
    "                word_after = word_after[:pos1] + \"_\" + word_after[pos1+1:pos2] + \"_\" + word_after[pos2+1:]        \n",
    "                \n",
    "            changes.append((word_before, word_after))\n",
    "                \n",
    "        else:\n",
    "            flag = 1 + (n % 10)\n",
    "            q = int(str(n)[0])\n",
    "            r = int(str(n)[1])\n",
    "            #print(\"-vv\", var, \"-q\", q, '-r', r)\n",
    "            l = 10 + q\n",
    "            word_change = modify_word(var, l)\n",
    "            word_before = word_change[\"before\"]\n",
    "            word_after = word_change[\"after\"]\n",
    "            #if word_before != word_after:\n",
    "            #    changes.append(word_change) \n",
    "            \n",
    "            if r == 0:\n",
    "                pos = np.random.choice(range(10, l))\n",
    "                word_after = word_after[:pos] + \"_\" + word_after[pos+1:]\n",
    "            else:\n",
    "                word_after = word_after[:r] + \"_\" + word_after[r+1:] \n",
    "                \n",
    "            changes.append((word_before, word_after))\n",
    "                   \n",
    "    return changes, flag\n",
    "\n",
    "def seekd_mlp(changed_vars, k):\n",
    "    msg = \"\"\n",
    "    for i, var in enumerate(changed_vars):\n",
    "        \n",
    "        if k == 0:\n",
    "            l = len(var)\n",
    "            \n",
    "            positions = []\n",
    "            start = 0\n",
    "            while True:\n",
    "                position = var.find('_', start)\n",
    "                if position == -1:\n",
    "                    break\n",
    "                positions.append(position)\n",
    "                start = position + 1\n",
    "            \n",
    "            #print(\"POSITIONS:\", positions)\n",
    "            \n",
    "            if l > 9:\n",
    "                l -= 10\n",
    "            if var[-1] == \"x\":\n",
    "                r = 0\n",
    "            elif len(positions) == 2:\n",
    "                r = 1 + positions[0]\n",
    "            else:\n",
    "                r = positions[0]\n",
    "            \n",
    "            value = l*10 + r\n",
    "        \n",
    "        else:\n",
    "            l = len(var)\n",
    "            a = k - l\n",
    "            l -= 10\n",
    "            r = var.index(\"_\")\n",
    "            if r > 9:\n",
    "                r = 0\n",
    "            value = l*100 + (r+10) + a\n",
    "            \n",
    "        char = chr(value)\n",
    "        msg += char\n",
    "    \n",
    "    return msg\n",
    "\n",
    "\n",
    "\n",
    "with open(\"init-code/init_long.py\", \"r\") as f:\n",
    "    code_example = f.read()\n",
    "\n",
    "key = \"LABORATORIA\"\n",
    "init_vars = retrieve_var_names(code_example, len(key)) \n",
    "\n",
    "\n",
    "changes, flag = hide_mlp(init_vars, key)\n",
    "for change in changes:\n",
    "    print(change)\n",
    "    \n",
    "print(\"FLAG:\", flag)\n",
    "\n",
    "print(\"SEEKING:\")\n",
    "vars = [x[1] for x in changes]\n",
    "msg = seekd_mlp(vars, flag)\n",
    "print(\"MSG:\", msg)\n",
    "\n",
    "print(\"CLOSE ENOUGH\")\n",
    "\n",
    "# TO DO - apply it to code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ Metoda 2: Hiding Data in Wordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testy nieparametryczne, które rozważaliśmy, oraz dlaczego są nieodpowiednie:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Test Wilcoxona (Wilcoxon Signed-Rank Test)**\n",
    "\n",
    "- **Opis**: Test Wilcoxona porównuje medianę różnic między dwiema zależnymi próbami. Używa rang różnic, a nie samych różnic, co czyni go odpornym na wpływ ekstremalnych wartości.\n",
    "  \n",
    "- **Dlaczego nie pasuje?**  \n",
    "  W przypadku naszych danych test Wilcoxona działa na rangach różnic, co oznacza, że wielkość procentowych różnic nie wpływa bezpośrednio na wynik. Ponieważ różnice są zawsze spadkowe w naszym przypadku (przed modyfikacją watermark zawsze wynosi 100%), test może nie być wystarczająco wrażliwy na istotne zmiany w wielkości różnic procentowych.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Test Znaków (Sign Test)**\n",
    "\n",
    "- **Opis**: Test Znaków analizuje, czy liczba pozytywnych różnic jest istotnie różna od liczby negatywnych różnic. Ignoruje jednak wielkość tych różnic.\n",
    "\n",
    "- **Dlaczego nie pasuje?**  \n",
    "  Test Znaków nie uwzględnia wielkości różnic, a jedynie ich kierunek (czy różnica jest dodatnia czy ujemna). W naszym przypadku wszystkie różnice są ujemne, co prowadzi do maksymalnego wyniku testu i braku różnic w p-wartościach, niezależnie od wielkości różnic procentowych.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Test McNemara**\n",
    "\n",
    "- **Opis**: Test McNemara jest używany do analizy danych binarnych dla prób zależnych, np. gdy chcemy sprawdzić, czy proporcja sukcesów przed i po interwencji różni się istotnie.\n",
    "\n",
    "- **Dlaczego nie pasuje?**  \n",
    "  Nasze dane są procentowe, a nie binarne. Test McNemara wymaga konwersji procentów na dane binarne (np. sukces/porażka przy ustalonej granicy), co prowadzi do utraty informacji o wielkości zmian i zbyt dużego uproszczenia danych.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Test Manna-Whitneya (Mann-Whitney U Test)**\n",
    "\n",
    "- **Opis**: Test Manna-Whitneya porównuje mediany dwóch niezależnych grup. Jest to nieparametryczny odpowiednik testu t-Studenta dla prób niezależnych.\n",
    "\n",
    "- **Dlaczego nie pasuje?**  \n",
    "  Nasze dane pochodzą z **prób zależnych** (przed i po modyfikacji tego samego kodu), więc test Manna-Whitneya nie jest odpowiedni. Ponadto test ten porównuje mediany dwóch grup, a nie różnice między nimi.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Test Permutacyjny**\n",
    "\n",
    "- **Opis**: Test permutacyjny polega na wielokrotnym losowym przekształcaniu danych w celu stworzenia rozkładu statystyki testowej, na podstawie którego można obliczyć p-wartość.\n",
    "\n",
    "- **Dlaczego nie pasuje?**  \n",
    "  W naszym przypadku test permutacyjny również może nie być odpowiedni, ponieważ wszystkie różnice są w tym samym kierunku (ujemne). To prowadzi do bardzo małych p-wartości, które są niemal stałe, niezależnie od wielkości zmian procentowych.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Test Kolmogorowa-Smirnova (K-S Test)**\n",
    "\n",
    "- **Opis**: Test K-S sprawdza, czy dwa zbiory danych pochodzą z tego samego rozkładu. Może być stosowany do porównywania dwóch rozkładów empirycznych.\n",
    "\n",
    "- **Dlaczego nie pasuje?**  \n",
    "  Próbka przed modyfikacją zawsze wynosi 100%, co prowadzi do skrajnie jednostajnego rozkładu. Nie ma sensu porównywać tego z próbką po modyfikacji, ponieważ różnica między rozkładami będzie trywialna i wynika z charakteru danych, a nie z ich statystycznej zmienności.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Test U (Mann-Whitney U Test dla różnic)**\n",
    "\n",
    "- **Opis**: Próba wykorzystania testu U do analizy różnic w zależnych próbach poprzez sztuczne rozdzielenie różnic na niezależne grupy.\n",
    "\n",
    "- **Dlaczego nie pasuje?**  \n",
    "  Test U wymaga niezależnych grup, a różnice w naszych danych są zależne (pochodzą z tych samych par). Przekształcanie różnic na dwie niezależne grupy jest błędne z punktu widzenia założeń testu.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m     plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[0;32m     41\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 43\u001b[0m \u001b[43mperform_stats\u001b[49m(differences)    \n",
      "Cell \u001b[1;32mIn[18], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m     plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[0;32m     41\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 43\u001b[0m \u001b[43mperform_stats\u001b[49m(differences)    \n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1697\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:634\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1112\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1090\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:494\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2185\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2182\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2184\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2185\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2187\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2190\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2254\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2251\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[0;32m   2252\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[1;32m-> 2254\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2255\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m   2257\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "before_modification = np.array([100, 100, 100, 100, 100, 100, 100, 100, 100, 100])\n",
    "after_modification = np.array([95, 85, 90, 92, 88, 93, 89, 87, 90, 88])\n",
    "\n",
    "differences = before_modification - after_modification\n",
    "\n",
    "def perform_stats(diff):\n",
    "\n",
    "    # Model Bayesowski\n",
    "    with pm.Model() as model:\n",
    "        # Priorytety\n",
    "        mu = pm.Normal(\"mu\", mu=0, sigma=10)\n",
    "        sigma = pm.HalfNormal(\"sigma\", sigma=10)\n",
    "\n",
    "        # Rozkład różnic\n",
    "        likelihood = pm.Normal(\"likelihood\", mu=mu, sigma=sigma, observed=diff)\n",
    "        trace = pm.sample(2000, return_inferencedata=True)\n",
    "\n",
    "    # posteriori\n",
    "    rope_min, rope_max = 0, 10\n",
    "    mu_samples = trace.posterior[\"mu\"].values.flatten()\n",
    "\n",
    "    # ROPE\n",
    "    within_rope = np.mean((mu_samples >= rope_min) & (mu_samples <= rope_max))\n",
    "    outside_rope = 1 - within_rope\n",
    "\n",
    "    print(f\"Prawdopodobieństwo, że zmiana mieści się w ROPE (0, 10): {within_rope:.2%}\")\n",
    "    print(f\"Prawdopodobieństwo, że zmiana jest istotna: {outside_rope:.2%}\")\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.hist(mu_samples, bins=30, density=True, alpha=0.7, color=\"skyblue\", label=\"Posteriori dla mu\")\n",
    "    plt.axvline(rope_min, color=\"red\", linestyle=\"--\", label=\"ROPE Min (0%)\")\n",
    "    plt.axvline(rope_max, color=\"red\", linestyle=\"--\", label=\"ROPE Max (10%)\")\n",
    "    plt.title(\"Rozkład posteriori dla średniej różnicy (mu)\")\n",
    "    plt.xlabel(\"Średnia różnica (mu)\")\n",
    "    plt.ylabel(\"Gęstość\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "perform_stats(differences)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zaproponowany test statystyczny\n",
    "\n",
    "Kod realizuje **podejście Bayesowskie** do analizy różnic procentowych, przy czym wykorzystuje narzędzie ROPE (Region of Practical Equivalence), aby ocenić, czy zmiana różnic (np. w watermarku) jest statystycznie i praktycznie istotna.\n",
    "\n",
    "#### 1. **Bayesowski test hipotez**:\n",
    "   - Kod realizuje analizę **Bayesowską**, która różni się od testów klasycznych (np. test t-Studenta, Wilcoxona):\n",
    "     - **Nie zakłada hipotezy zerowej** (że nie ma efektu) ani alternatywnej.\n",
    "     - Zamiast tego estymuje rozkład posteriori dla interesujących nas parametrów (\\( \\mu \\), \\( \\sigma \\)).\n",
    "   - Wynik analizy ROPE:\n",
    "     - Jeśli większość posteriori mieści się w przedziale ROPE, możemy powiedzieć, że zmiana jest nieistotna **w sensie praktycznym**.\n",
    "     - Jeśli wartości są poza ROPE, zmiana jest praktycznie istotna.\n",
    "\n",
    "#### 2. **Nieparametryczne podejście**:\n",
    "   - Bayesowskie modele pozwalają elastycznie dopasować rozkład posteriori bez założeń o normalności danych (choć w tym przykładzie użyto rozkładu normalnego dla uproszczenia).\n",
    "\n",
    "#### 3. **Test istotności dla różnic (poprzez ROPE)**:\n",
    "   - Zamiast sprawdzać tylko, czy różnice są statystycznie istotne (jak w klasycznych testach p-wartości), ten test bada również **praktyczną istotność**.\n",
    "   - Pozwala to włączyć wiedzę ekspercką (np. \\( 10\\% \\) jako akceptowalny spadek) do procesu decyzyjnego.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "#### Watermarkowanie\n",
    "- watermark z dokumentu \n",
    "- engine do watermarkowania (priorytet)\n",
    "- engine do oceny watermarku\n",
    "\n",
    "#### Badanie zmian\n",
    "- przygotowanie datasetu(oraz kodu do uruchomienia wszystkiego)\n",
    "- uzycie statystyki\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watermark_code(filename):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_watermark(filename):\n",
    "    return 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores before modification:\n",
      "file1.py: 80%\n",
      "file2.py: 80%\n",
      "file3.py: 80%\n",
      "file4.py: 80%\n",
      "file5.py: 80%\n",
      "file6.py: 80%\n",
      "file7.py: 80%\n",
      "file8.py: 80%\n",
      "file9.py: 80%\n",
      "file10.py: 80%\n",
      "\n",
      "Scores after modification:\n",
      "file1.py_watermark_change.py: No file found%\n",
      "file2.py_watermark_change.py: No file found%\n",
      "file3.py_watermark_change.py: No file found%\n",
      "file4.py_watermark_change.py: No file found%\n",
      "file5.py_watermark_change.py: No file found%\n",
      "file6.py_watermark_change.py: No file found%\n",
      "file7.py_watermark_change.py: No file found%\n",
      "file8.py_watermark_change.py: No file found%\n",
      "file9.py_watermark_change.py: No file found%\n",
      "file10.py_watermark_change.py: No file found%\n",
      "Nie można obliczyć różnic - różna liczba wyników przed i po modyfikacji.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def watermark_and_score(files):\n",
    "    before_modification = []\n",
    "    after_modification = []\n",
    "\n",
    "    for file in files:\n",
    "        watermarked_file = f\"{file}_watermark.py\"\n",
    "\n",
    "        watermark_code(file)\n",
    "\n",
    "        before_score = score_watermark(watermarked_file)\n",
    "        before_modification.append((file, before_score))\n",
    "\n",
    "        modified_file = f\"{file}_watermark_change.py\"\n",
    "        if os.path.exists(modified_file):\n",
    "            after_score = score_watermark(modified_file)\n",
    "            after_modification.append((modified_file, after_score))\n",
    "        else:\n",
    "            after_modification.append((modified_file, None))\n",
    "\n",
    "    return before_modification, after_modification\n",
    "\n",
    "python_files = [f\"file{i}.py\" for i in range(1, 11)]\n",
    "\n",
    "before_modification, after_modification = watermark_and_score(python_files)\n",
    "\n",
    "print(\"Scores before modification:\")\n",
    "before_scores = []\n",
    "after_scores = []\n",
    "for file, score in before_modification:\n",
    "    print(f\"{file}: {score}%\")\n",
    "    before_scores.append(score)\n",
    "\n",
    "print(\"\\nScores after modification:\")\n",
    "for file, score in after_modification:\n",
    "    print(f\"{file}: {score if score is not None else 'No file found'}%\")\n",
    "    if score is not None:\n",
    "        after_scores.append(score)\n",
    "if len(before_scores) == len(after_scores):\n",
    "    diff = np.array(before_scores) - np.array(after_scores)\n",
    "    perform_stats(diff)\n",
    "else:\n",
    "    print(\"Nie można obliczyć różnic - różna liczba wyników przed i po modyfikacji.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Znakowanie i identyfikacja kodu wygenerowanego przez AI\n",
    "\n",
    "Temat automatycznej generacji kodu źródłowego przez Sztuczną Inteliencję (AI) jest obszerny i obejmuje różne techniki, modele oraz zastosowania. Przedmiotem naszego zainteresowania na kursie jest natomiast znalezienie sposobu na zrozumienie czy popularne generatory kodu (i ogólnego użycia) tworzą go w specyficzny dla siebie sposób, i jak tak to jaki. Chcemy odpowiedzieć na pytanie czy w dostarczonym kodzie można odnaleźć pewne statystyczne wzorce - czyli, czy AI posiada swój styl mogący go później zidentyfikować jako autora - podobnie do programistów.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naszą pierwszą czynnością było wygenerowanie kilku prostych matematycznych funkcji i algorytmów w języku Python przy użyciu ChatGPT. Już na pierwszy rzut okna dało się zauważyć pewne elementy, które mogłyby odbiegać od *normy*:\n",
    "- kod nie korzysta możliwości Pythona co do pisania zwięzłych i bardziej złożonych struktur syntaktycznych\n",
    "- przy każdej operacji pojawia się komentarz zaczynający się od wielkiej litery, a zmienne wykorzystywane mają dokładnie taką nazwę jak w komentarzu\n",
    "\n",
    "Celem jest znalezienie **statystycznego** potwierdzenia naszej intuicji, oraz znalezienie **ukrytych artefaktów** o ile istnieją - za pomocą różnych metod i narzędzie programistycznych.\n",
    "\n",
    "Zadanie detekcji, czy dany fragement kodu został napisany przez AI okazał się niezbyt dobrze opisanym w literaturze tematem, a przynajmniej takie odnieślismy wrażenie. Większość artykułów dotyczyło danych w postaci **tekstowej**. Kod oczywiście również jest zapisany w postaci tekstowej, jednak języki programowania ze względu na swoje przeznaczenie różnią się w aspektach gramatycznych i składniowych, które potrafiły być czynnikiem decydującym o decyzji czy badany tekst jest dziełem człowieka czy AI.\n",
    "Wyżej wymienione przypuszczenia przykuły też uwagę innych badaczy [1](https://arxiv.org/abs/2405.16133), którzy również zwrócili uwagę na dysproporcję w dokumentacji wykrywania wygenerowanych przez AI fragmentów kodu a tekstu i niedostępności datasetów - co było trochę oczekiwane, ponieważ dopiero od w miare niedługiego okresu, rozwiązania AI stały się użytecznym narzędziem a zarazem problemem.\n",
    "\n",
    "W swoim artykule zaprezentowali metodę wykrywania polegającą na porównaniu przepisywania przez AI kodu przygotowanego przez 1. człowieka i 2. ai. \n",
    "\n",
    "![llm rewriting](./assets/llmrewriting.png)\n",
    "\n",
    "Dzięki tej obserwacji przygotowali dataset z sztucznie wygenerowanymi funkcjami, z którego możemy skorzystać. Jednak zdecydowali się nauczyć model, a my chcemy **deterministycznie** znaleźć te różnice.\n",
    "\n",
    "W innym znalezionym badaniu [2](https://ieeexplore.ieee.org/document/9674263/), badacze zdecydowali się stworzyć algorytm heurystyczny, który uwzględniał analizę programów z repozytoriów.\n",
    "\n",
    "![heurystyka](./assets/heurystyka.png)\n",
    "\n",
    "Na jego podobieństwo zbudowaliśmy własny algorytm heurystyczny, który mimo swojej prostoty i małej próbki danych potrafił wskazać na pochodzenie syntetyczne lub nie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Analysis for code_samples/ai/binary_search.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/bubble_sort.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/factorial.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/fib.py ===\n",
      "'AI Generated Probability (%): 88.89\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/is_prime.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/palindrome.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "=== Analysis for code_samples/human/binary_search.py ===\n",
      "'AI Generated Probability (%): 66.67\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/bubble_sort.py ===\n",
      "'AI Generated Probability (%): 44.44\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/factorial.py ===\n",
      "'AI Generated Probability (%): 33.33\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/fib.py ===\n",
      "'AI Generated Probability (%): 44.44\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/is_prime.py ===\n",
      "'AI Generated Probability (%): 44.44\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/palindrome.py ===\n",
      "'AI Generated Probability (%): 33.33\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def analyze_code_heuristic(code, filename):\n",
    "    results = {\"Filename\": filename}\n",
    "\n",
    "    # Keyword Distribution\n",
    "    keywords = ['if', 'else', 'for', 'while', 'def', 'class', 'try', 'except']\n",
    "    keyword_distribution = {kw: len(re.findall(r'\\b' + kw + r'\\b', code)) for kw in keywords}\n",
    "    results[\"Keyword Distribution\"] = keyword_distribution\n",
    "\n",
    "    # Naming Conventions\n",
    "    pascal_case = len(re.findall(r'\\b[A-Z][a-z]*[A-Z][a-z]*\\b', code))\n",
    "    snake_case = len(re.findall(r'\\b[a-z]+(_[a-z]+)+\\b', code))\n",
    "    results[\"Naming Conventions\"] = {\"PascalCase\": pascal_case, \"snake_case\": snake_case}\n",
    " \n",
    "    # Comment Analysis\n",
    "    comments = re.findall(r'#.*', code)\n",
    "    average_comment_length = sum(len(comment) for comment in comments) / len(comments) if comments else 0\n",
    "    overly_detailed_comments = sum(1 for comment in comments if len(comment) > 40)\n",
    "    results[\"Comments\"] = {\n",
    "        \"Total Comments\": len(comments),\n",
    "        \"Average Length\": average_comment_length,\n",
    "        \"Overly Detailed Comments\": overly_detailed_comments\n",
    "    }\n",
    "\n",
    "    # Cyclomatic Complexity\n",
    "    tree = ast.parse(code)\n",
    "    complexity = 1\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, (ast.If, ast.For, ast.While, ast.Try, ast.FunctionDef)):\n",
    "            complexity += 1\n",
    "    results[\"Cyclomatic Complexity\"] = complexity\n",
    "\n",
    "    # Code Duplication Detection\n",
    "    def find_duplicate_functions(tree):\n",
    "        function_names = defaultdict(list)\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.FunctionDef):\n",
    "                function_names[node.name].append(ast.get_source_segment(code, node))\n",
    "\n",
    "        duplicates = {name: func_code for name, func_code in function_names.items() if len(func_code) > 1}\n",
    "        return duplicates\n",
    "\n",
    "    duplicates = find_duplicate_functions(tree)\n",
    "    results[\"Duplicate Functions\"] = {name: len(funcs) for name, funcs in duplicates.items()}\n",
    "\n",
    "    # Repetitive Patterns Check\n",
    "    repetitive_patterns = re.findall(r'\\b\\w+\\b', code)\n",
    "    repetitive_count = len([word for word in repetitive_patterns if repetitive_patterns.count(word) > 3])\n",
    "    results[\"Repetitive Patterns\"] = repetitive_count\n",
    "\n",
    "    # Variable & Function Naming Analysis\n",
    "    overly_descriptive_names = sum(\n",
    "        1 for name in re.findall(r'\\b[a-zA-Z_]{10,}\\b', code) if '_' in name\n",
    "    )\n",
    "    results[\"Overly Descriptive Names\"] = overly_descriptive_names\n",
    "\n",
    "    # Simple Logic and Default Values\n",
    "    default_values = len(re.findall(r'\\b=\\s*[\\'\\\"\\d\\[\\]\\{\\}\\(\\)]', code))\n",
    "    results[\"Default Values\"] = default_values\n",
    "\n",
    "    # Exception Handling\n",
    "    exception_handlers = len(re.findall(r'\\btry\\b.*?\\bexcept\\b', code, re.DOTALL))\n",
    "    results[\"Exception Handling\"] = exception_handlers\n",
    "\n",
    "    # AI Generated Probability\n",
    "    ai_score = 0\n",
    "    total_weight = 9\n",
    "\n",
    "    ai_score += (complexity < 10) * (1 / total_weight)\n",
    "    ai_score += (average_comment_length > 15) * (2 / total_weight)\n",
    "    ai_score += (pascal_case == 0) * (1 / total_weight)\n",
    "    ai_score += (snake_case > 0) * (1 / total_weight)\n",
    "    ai_score += (len(duplicates) > 0) * (0.5 / total_weight)\n",
    "    ai_score += (repetitive_count > 5) * (1 / total_weight)\n",
    "    ai_score += (overly_descriptive_names > 2) * (1 / total_weight)\n",
    "    ai_score += (default_values > 2) * (0.5 / total_weight)\n",
    "    ai_score += (exception_handlers <= 2) * (1 / total_weight)\n",
    "\n",
    "    ai_probability = ai_score * 100\n",
    "    results[\"AI Generated Probability (%)\"] = round(ai_probability, 2)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def analyze_directory(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".py\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, 'r') as file:\n",
    "                code = file.read()\n",
    "                results = analyze_code_heuristic(code, filename)\n",
    "\n",
    "                print(f\"=== Analysis for {directory}/{filename} ===\")\n",
    "                # for key, value in results.items():\n",
    "                #     print(f\"{key}: {value}\")\n",
    "                print(f\"'AI Generated Probability (%): {results['AI Generated Probability (%)']}\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "\n",
    "analyze_directory('code_samples/ai')\n",
    "print(\"========================\\n\")\n",
    "analyze_directory('code_samples/human')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla przygotowanych - małolicznych próbek, obliczone prawdopodobieństwa przyjmują zauważalnie wyższe wartości dla syntetycznych kodów\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Znakowanie kodu\n",
    "\n",
    "W trakcie zajęć lekko zmodyfikowano temat projektu, mianowicie odeszliśmy od zagadnienia wygenerowanych kodów, na rzecz znakowania **naszego** kodu. Celem jest teraz poszukiwanie i implementacja znanych metod do watermarkingu, by można było przekazać kod funkcji markującej a następnie dało się potwierdzić istnienie nałożonych przez nas wzorów.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Niewidzialne znaki końca linii SPACE 0, TAB 1\n",
    "\n",
    "Kolejnym etapem jest skupienie się na sposobie zakodowania kodu - spróbowaliśmy zawrzeć wzorzec do kodu. Mianowicie, dla wybranego tekstu kodu, w co drugiej linijce dodajemy spację lub tabulator do końca linii. Te znaki będą nam mówić o wartości bitu. \n",
    "- spacja = 0\n",
    "- tab = 1\n",
    "\n",
    "Znaki są ustawiane w taki sposób, aby odczytując kod z góry do dołu tworzyły nam się bloki bajtowe, które są kodem litery naszego hasła.\n",
    "Limitacją na razie jest długość kodu i długość hasła, ale to będzie ulepszane. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watermark ['L', 'A', 'B', 'O', 'R', 'A', 'T', 'O', 'R', 'I', 'A']\n",
      "Watermark binary: 01001100x01000001x01000010x01001111x01010010x01000001x01010100x01001111x01010010x01001001x01000001\n",
      "Dlugosc watermarku: 11\n",
      "Dlugosc binarna watermarku: 88\n",
      "\n",
      "BINARY PATTERN ['0', '1', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '1', '0', '1', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '1', '0', '1', '0', '1', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '1', '0', '1', '0', '0', '1', '0', '0', '1', '0', '0', '1', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '1']\n",
      "Znaleziony kod: LABORATORIALAB\n"
     ]
    }
   ],
   "source": [
    "def add_watermark_space_tab(code, watermark=\"LABORATORIA\"):\n",
    "    \n",
    "    watermark_space_tab_list = ['\\t' if bit == '1' else ' ' for bit in ''.join(format(ord(c), '08b') for c in watermark)]\n",
    "    watermark_binary = 'x'.join([ format(ord(c), '08b') for c in watermark])\n",
    "    watermark_list = list(watermark)\n",
    "    \n",
    "    print(\"Watermark\", watermark_list)\n",
    "    print(\"Watermark binary:\", watermark_binary)\n",
    "    #print(\"Watermark char list:\", watermark_space_tab_list)\n",
    "    print('Dlugosc watermarku: ' + str(len(watermark)))\n",
    "    print('Dlugosc binarna watermarku: ' + str(len(watermark_space_tab_list)))\n",
    "    print()\n",
    "    \n",
    "    lines = code.splitlines()\n",
    "    \n",
    "    \n",
    "    # -------------------\n",
    "    # code length aware\n",
    "    \n",
    "    # every 2 lines, so scope is n*len(watermark_space_tab_list)\n",
    "    n = 2\n",
    "    \n",
    "    if len(lines) > n * len(watermark_space_tab_list):\n",
    "        \n",
    "        needed_bites = len(lines) // n\n",
    "        current_bites = len(watermark_space_tab_list)\n",
    "        \n",
    "        bites_to_add = needed_bites - current_bites\n",
    "        \n",
    "        # ile liter potrzebnych\n",
    "        m = bites_to_add // 8\n",
    "        # litery + 1 by nie bawić się w części\n",
    "        m = m + 1\n",
    "        \n",
    "        # ile tych liter do czesc watermarka\n",
    "        k = m // len(watermark_list)\n",
    "        r = m % len(watermark_list)\n",
    "        \n",
    "        watermark_list += k * watermark_list\n",
    "        watermark_list += watermark_list[:r]\n",
    "        \n",
    "        watermark_space_tab_list = ['\\t' if bit == '1' else ' ' for bit in ''.join(format(ord(c), '08b') for c in watermark_list)]\n",
    "        \n",
    "            \n",
    "    # -------------------\n",
    "    \n",
    "    for i in range(1, len(lines), n):\n",
    "        lines[i] += watermark_space_tab_list[i // n]\n",
    "            \n",
    "    \n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "\n",
    "def extract_watermark_space_tab(code):\n",
    "    lines = code.splitlines()\n",
    "\n",
    "    binary_pattern = []\n",
    "    for i in range(1, len(lines), 2):\n",
    "        if lines[i].endswith(\" \") or lines[i].endswith(\"\\t\"):\n",
    "            last_char = lines[i][-1]\n",
    "            binary_pattern.append('1' if last_char == '\\t' else '0')\n",
    "\n",
    "    print(\"BINARY PATTERN\", binary_pattern)\n",
    "    watermark_text = ''\n",
    "    for i in range(0, len(binary_pattern), 8):\n",
    "        byte = ''.join(binary_pattern[i:(i + 8)])\n",
    "        if len(byte) == 8:\n",
    "            watermark_text += chr(int(byte, 2))\n",
    "\n",
    "    return watermark_text if watermark_text else \"Brak znaku wodnego\"\n",
    "\n",
    "\n",
    "with open(\"init-code/init_long.py\", \"r\") as f:\n",
    "    code_example = f.read()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "watermarked_code = add_watermark_space_tab(code_example)\n",
    "#print(\"Zwatermarkowany kod:\\n\" + watermarked_code)\n",
    "\n",
    "detected_watermark = extract_watermark_space_tab(watermarked_code)\n",
    "print(\"Znaleziony kod:\", detected_watermark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Sortowanie importów\n",
    "\n",
    "Poniższy kod realizuje dodanie watermarka do sekcji importow w taki sposob ze sortuje je wedlug hash'a `sha256`. \\\n",
    "Widoczna jest również metoda która sprawdza czy zmieniony kod zawiera w sobie watermarka.\n",
    "\n",
    "Obserwujemy również wyniki:\n",
    "\n",
    "Czy kod zawiera watermark?\n",
    "True\n",
    "\n",
    "Czy oryginalny kod zawiera watermark?\n",
    "False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kod po dodaniu watermarku:\n",
      "\n",
      "from math import sqrt\n",
      "import os\n",
      "from itertools import permutations\n",
      "import sys\n",
      "from collections import defaultdict\n",
      "\n",
      "\n",
      "\n",
      "def example_function():\n",
      "    print(\"Hello, World!\")\n",
      "    return 42\n",
      "\n",
      "def calculate_square_root(x):\n",
      "    return sqrt(x)\n",
      "\n",
      "def list_permutations(iterable):\n",
      "    return list(permutations(iterable))\n",
      "    \n",
      "\n",
      "Czy kod zawiera watermark?\n",
      "True\n",
      "\n",
      "Czy oryginalny kod zawiera watermark?\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "def add_watermark_in_imports(code, watermark):\n",
    "    lines = code.splitlines()\n",
    "    \n",
    "    imports = [line for line in lines if line.startswith(\"import\") or line.startswith(\"from\")]\n",
    "    other_lines = [line for line in lines if not (line.startswith(\"import\") or line.startswith(\"from\"))]\n",
    "    \n",
    "    # hash\n",
    "    watermark_hash = hashlib.sha256(watermark.encode()).hexdigest()\n",
    "    # sort\n",
    "    sorted_imports = sorted(imports, key=lambda x: hashlib.sha256((x + watermark_hash).encode()).hexdigest())\n",
    "    return '\\n'.join(sorted_imports + other_lines)\n",
    "\n",
    "def is_watermarked_imports(code, watermark):\n",
    "    lines = code.splitlines()\n",
    "    \n",
    "    imports = [line for line in lines if line.startswith(\"import\") or line.startswith(\"from\")]\n",
    "    \n",
    "    watermark_hash = hashlib.sha256(watermark.encode()).hexdigest()\n",
    "    sorted_imports = sorted(imports, key=lambda x: hashlib.sha256((x + watermark_hash).encode()).hexdigest())\n",
    "    \n",
    "    return imports == sorted_imports\n",
    "\n",
    "\n",
    "example_code = \"\"\"\n",
    "\n",
    "import os\n",
    "from math import sqrt\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from itertools import permutations\n",
    "\n",
    "def example_function():\n",
    "    print(\"Hello, World!\")\n",
    "    return 42\n",
    "\n",
    "def calculate_square_root(x):\n",
    "    return sqrt(x)\n",
    "\n",
    "def list_permutations(iterable):\n",
    "    return list(permutations(iterable))\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "watermarked_code = add_watermark_in_imports(example_code, \"UniqueWatermark2024\")\n",
    "print(\"Kod po dodaniu watermarku:\\n\")\n",
    "print(watermarked_code)\n",
    "\n",
    "print(\"\\nCzy kod zawiera watermark?\")\n",
    "is_watermarked = is_watermarked_imports(watermarked_code, \"UniqueWatermark2024\")\n",
    "print(is_watermarked)\n",
    "\n",
    "print(\"\\nCzy oryginalny kod zawiera watermark?\")\n",
    "not_watermarked = is_watermarked_imports(example_code, \"UniqueWatermark2024\")\n",
    "print(not_watermarked)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Dodawanie *stylu*\n",
    "\n",
    "Poniższy kod realizuje zamiane znaków w ich podobne odpowiedniki np. `l -> 1` \\\n",
    "Kod pomija wbudowane nazwy oraz pomija pierwsze znaki po to, żeby możliwa była kompilacja zwatermarkowanego kodu. \\\n",
    "Przykładowa zmiana nazwy zmiennej `total -> tota1`. \\\n",
    "Dodatkowo dodana została funkcja sprawdzająca watermark.\n",
    "\n",
    "Przykładowy wynik:\n",
    "Czy kod zawiera watermark w zmiennych i parametrach?\n",
    "True\n",
    "\n",
    "Czy oryginalny kod zawiera watermark w zmiennych i parametrach?\n",
    "False\n",
    "\n",
    "Problemem może być brak estetyczności kodu, i wyraźną chęć przepisania bądź zmiany nazw zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kod po dodaniu watermarku z podobnymi znakami:\n",
      "\n",
      "\n",
      "\n",
      "def calcul@te_ar3a(length, width):\n",
      "    result = length * width\n",
      "    return result\n",
      "\n",
      "def greet_user(name):\n",
      "    greeting = f\"Hello, {name}!\"\n",
      "    print(greeting)\n",
      "\n",
      "def comput3_sum(number5):\n",
      "    total = 0\n",
      "    print(\"--\")\n",
      "    for num in number5:\n",
      "        total += num\n",
      "    print(total)\n",
      "    return total\n",
      "    \n",
      "\n",
      "Czy kod zawiera watermark w zmiennych i parametrach?\n",
      "True\n",
      "\n",
      "Czy oryginalny kod zawiera watermark w zmiennych i parametrach?\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import re\n",
    "import keyword\n",
    "\n",
    "SIMILAR_CHARS = {\n",
    "    'a': '@',\n",
    "    'e': '3',\n",
    "    'i': '1',\n",
    "    'o': '0',\n",
    "    'l': '1',\n",
    "    's': '5',\n",
    "    't': '7'\n",
    "}\n",
    "\n",
    "BUILTINS = dir(__builtins__)\n",
    "\n",
    "def add_watermark_in_variables_similar_chars(code, watermark):\n",
    "\n",
    "    # wsm to ten hash nie jest wykorzystywany skoro i jak dajemy len(watermark_hash) ()= 4) jako warunek sprawdzający można by dodać jakoś zmienić na idk // 1000 \n",
    "    watermark_hash = hashlib.sha256(watermark.encode()).hexdigest()[:4]\n",
    "    #print(\"W HASH:\", watermark_hash, type(watermark_hash))\n",
    "    #hash_n = int(watermark_hash[0])\n",
    "    hash_n = int(re.sub(r'\\D', '1', watermark_hash)[0])\n",
    "    \n",
    "    def modify_variable(name):\n",
    "        if name in keyword.kwlist or name in BUILTINS:\n",
    "            return name\n",
    "        \n",
    "        modified_name = name[0]\n",
    "        for i, char in enumerate(name[1:], 1):\n",
    "            if char.lower() in SIMILAR_CHARS and i % hash_n == 0:\n",
    "                modified_name += SIMILAR_CHARS[char.lower()]\n",
    "            else:\n",
    "                modified_name += char\n",
    "        return modified_name\n",
    "\n",
    "    variable_pattern = re.compile(r'\\b([a-zA-Z_][a-zA-Z0-9_]*)\\b')\n",
    "    lines = code.splitlines()\n",
    "    updated_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        updated_line = variable_pattern.sub(\n",
    "            lambda match: modify_variable(match.group(1)), line)\n",
    "        \n",
    "        updated_lines.append(updated_line)\n",
    "    \n",
    "    return '\\n'.join(updated_lines)\n",
    "\n",
    "def is_watermarked_variables_similar_chars(code, watermark):\n",
    "\n",
    "    watermark_hash = hashlib.sha256(watermark.encode()).hexdigest()[:4]\n",
    "    #hash_n = int(watermark_hash[0])\n",
    "    hash_n = int(re.sub(r'\\D', '1', watermark_hash)[0])\n",
    "    \n",
    "    def check_variable(name):\n",
    "\n",
    "        original_name = name[0]\n",
    "        for i, char in enumerate(name[1:], 1):\n",
    "            if char in SIMILAR_CHARS.values() and i % hash_n == 0:\n",
    "                original_char = next((k for k, v in SIMILAR_CHARS.items() if v == char), None)\n",
    "                if original_char:\n",
    "                    original_name += original_char\n",
    "                else:\n",
    "                    return False\n",
    "            else:\n",
    "                original_name += char\n",
    "        \n",
    "        return original_name != name\n",
    "\n",
    "    variable_pattern = re.compile(r'\\b([a-zA-Z_][a-zA-Z0-9_]*)\\b')\n",
    "    for match in variable_pattern.findall(code):\n",
    "        if check_variable(match):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "example_code = \"\"\"\n",
    "\n",
    "def calculate_area(length, width):\n",
    "    result = length * width\n",
    "    return result\n",
    "\n",
    "def greet_user(name):\n",
    "    greeting = f\"Hello, {name}!\"\n",
    "    print(greeting)\n",
    "\n",
    "def compute_sum(numbers):\n",
    "    total = 0\n",
    "    print(\"--\")\n",
    "    for num in numbers:\n",
    "        total += num\n",
    "    print(total)\n",
    "    return total\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "watermark_vars = \"ImprovedWatermark2024x\"\n",
    "\n",
    "watermarked_code = add_watermark_in_variables_similar_chars(example_code, watermark_vars)\n",
    "print(\"Kod po dodaniu watermarku z podobnymi znakami:\\n\")\n",
    "print(watermarked_code)\n",
    "\n",
    "print(\"\\nCzy kod zawiera watermark w zmiennych i parametrach?\")\n",
    "is_watermarked = is_watermarked_variables_similar_chars(watermarked_code, watermark_vars)\n",
    "print(is_watermarked)\n",
    "\n",
    "print(\"\\nCzy oryginalny kod zawiera watermark w zmiennych i parametrach?\")\n",
    "not_watermarked = is_watermarked_variables_similar_chars(example_code, watermark_vars)\n",
    "print(not_watermarked)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Inne niewidzialne znaki\n",
    "\n",
    "Następnymi krokami, które chcieliśmy przetestować to:\n",
    "\n",
    "- dodawanie znaku NULL (char - 0) lub Zero-Width Space (utf-8 200B), do każdego stringu obecnego w kodzie. \n",
    "    \n",
    "\n",
    "- dodawanie zmiennej liczby znaków wybranych znaków do każdej linii, tak aby nawet po usunięciu kilku linijek, po odczytaniu liczby tych znaków można by spróbować statystycznie zweryfikować czy te dane pochodzą z wybranego przez nas rozkładu. Zapewne musiałby byc to rozkład normalny, ale z niezbyt dużą wartością średnią, żeby edytor kodu nie był w stanie wykryć *slidera*. Ale może gdyby dodawać znaku null to można by je dodawać z innego rozkładu - i to w kontekście każdej napotkanej funkcji, głównie wokół których zorganizowany jest kod. Takie sprawdzenie moglibyśmy zweryfikować m.in. szukając nadjdłuższego wspoólnego podciągu LCS...\n",
    "\n",
    "<br>\n",
    "\n",
    "Jednak eksperyment z użyciem innych znaków białych **nie** działają jak zakładaliśmy, Python ma w tym elemencie surową politykę i dodane znaki na końcu linii powodują widoczne w popularnych ide zmiany, które dodatkowo  uniemożliwiają działanie kodu, więc zostają **PORZUCONE** na ten moment i zostajemy przy neutralnych `\" \"` i `\"\\t\"`. Dodatkowo, mechanizm kopiujący jak napotyka znak NULL to w tym miejscu kończy stringa, którego kopiuje, więc i ta funkcjonalność uniemożliwia płynną pracę z kodem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEN LINE BEFORE: 15\n",
      "LEN LINES AFTER: 18\n",
      "-\n",
      "LEN LINE BEFORE: 0\n",
      "LEN LINES AFTER: 3\n",
      "-\n",
      "LEN LINE BEFORE: 19\n",
      "LEN LINES AFTER: 22\n",
      "-\n",
      "LEN LINE BEFORE: 13\n",
      "LEN LINES AFTER: 17\n",
      "-\n",
      "LEN LINE BEFORE: 20\n",
      "LEN LINES AFTER: 24\n",
      "-\n",
      "LEN LINE BEFORE: 14\n",
      "LEN LINES AFTER: 17\n",
      "-\n",
      "LEN LINE BEFORE: 19\n",
      "LEN LINES AFTER: 22\n",
      "-\n",
      "LEN LINE BEFORE: 17\n",
      "LEN LINES AFTER: 19\n",
      "-\n",
      "LEN LINE BEFORE: 20\n",
      "LEN LINES AFTER: 22\n",
      "-\n",
      "LEN LINE BEFORE: 0\n",
      "LEN LINES AFTER: 2\n",
      "-\n",
      "LEN LINE BEFORE: 42\n",
      "LEN LINES AFTER: 45\n",
      "-\n",
      "LEN LINE BEFORE: 22\n",
      "LEN LINES AFTER: 25\n",
      "-\n",
      "LEN LINE BEFORE: 24\n",
      "LEN LINES AFTER: 27\n",
      "-\n",
      "LEN LINE BEFORE: 0\n",
      "LEN LINES AFTER: 4\n",
      "-\n",
      "LEN LINE BEFORE: 15\n",
      "LEN LINES AFTER: 17\n",
      "-\n",
      "P1: [0, 3, 1, 3, 3, 1, 2, 3, 0, 1, 2, 2, 0, 3, 3]\n",
      "P2: [0, 3, 1, 3, 3, 1, 2, 3, 0, 1, 2, 2, 0, 3, 3]\n",
      "\n",
      "Code with null watermark:\n",
      "\n",
      "def isprime(n):\u0000\u0000\n",
      "\u0000\u0000\n",
      "    n = abs(int(n))\u0000\u0000\n",
      "    if n < 2:\u0000\u0000\u0000\n",
      "        return False\u0000\u0000\u0000\n",
      "    if n == 2:\u0000\u0000\n",
      "        return True\u0000\u0000\n",
      "    if not n & 1:\u0000\n",
      "        return False\u0000\n",
      "\u0000\n",
      "    for x in range(3, int(n**0.5) + 1, 2):\u0000\u0000\n",
      "        if n % x == 0:\u0000\u0000\n",
      "            return False\u0000\u0000\n",
      "\u0000\u0000\u0000\n",
      "    return True\u0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import hashlib\n",
    "import re\n",
    "    \n",
    "\n",
    "def add_multiple_inv_sign_watermark(code, watermark):\n",
    "\n",
    "    watermark_hash = hashlib.sha256(watermark.encode()).hexdigest()[:4]\n",
    "      \n",
    "    hash_n = int(re.sub(r'\\D', '1', watermark_hash))\n",
    "    random.seed(hash_n)\n",
    "    \n",
    "    pattern = []\n",
    "    lines = code.splitlines()\n",
    "    for i in range(len(lines)):\n",
    "        n = random.choice(range(4))\n",
    "        lines[i] += n * \" \"     \n",
    "        pattern.append(n)       \n",
    "\n",
    "    return '\\n'.join(lines), pattern\n",
    "\n",
    "\n",
    "\n",
    "def add_null_watermark(code):\n",
    "\n",
    "    lines = code.splitlines()\n",
    "    for i in range(len(lines)):\n",
    "        print(\"LEN LINE BEFORE:\", len(lines[i]))\n",
    "        lines[i] += random.choice(range(1,4))*chr(0) + \"\\n\"\n",
    "            \n",
    "        print(\"LEN LINES AFTER:\", len(lines[i]))\n",
    "        print(\"-\")\n",
    "\n",
    "    return ''.join(lines)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "def add_zws_watermark(code):\n",
    "\n",
    "    lines = code.splitlines()\n",
    "    for i in range(len(lines)):\n",
    "        print(\"LEN LINE BEFORE:\", len(lines[i]))\n",
    "        lines[i] += random.choice(range(1,4))*\"\\u200B\"\n",
    "            \n",
    "        print(\"LEN LINES AFTER:\", len(lines[i]))\n",
    "        print(\"-\")\n",
    "\n",
    "    return ''.join(lines)\n",
    "'''\n",
    "\n",
    "def extract_multiple_inv_signs_watermark(code):\n",
    "    \n",
    "    pattern = []\n",
    "    lines = code.splitlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        x = re.findall(r\" *$\", line)\n",
    "        pattern.append(len(x[0]))   \n",
    "         \n",
    "    return pattern\n",
    "\n",
    "    \n",
    "def get_func(filepath):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        code_example = f.read()\n",
    "\n",
    "    return code_example\n",
    "\n",
    "def save_func(filepath, code):\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(code)\n",
    "        \n",
    "    \n",
    "watermark_dist = \"ImprovedWatermark2024x\"\n",
    "   \n",
    "filename1 = \"./code_samples/human/is_prime.py\"\n",
    "filename2 = \"./watermarked_code/is_prime_w1.py\"\n",
    "\n",
    "filename_null = \"./watermarked_code/is_prime_null.py\"\n",
    "\n",
    "code_watermarked = get_func(filename1)\n",
    "watermarked_code, original_pattern = add_multiple_inv_sign_watermark(code_watermarked, watermark_dist)\n",
    "watermarked_null_code = add_null_watermark(code_watermarked)\n",
    "    \n",
    "save_func(filename2, watermarked_code)\n",
    "save_func(filename_null, watermarked_null_code)\n",
    "\n",
    "print(\"P1:\", original_pattern)\n",
    "\n",
    "extracted_pattern = extract_multiple_inv_signs_watermark(watermarked_code)\n",
    "\n",
    "print(\"P2:\", extracted_pattern)\n",
    "\n",
    "\n",
    "print(\"\\nCode with null watermark:\\n\")\n",
    "print(watermarked_null_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porównanie 2 uzyskanych wzorców:\n",
    "- użyty do zakodowania różnej informacji o spacjach, np. P1: [0, 3, 1, 3, 3, 1, 2, 3, 0, 1, 2, 2, 0, 3, 3]\n",
    "- odczytany z kodu, np. P2: [0, 3, 1, 3, 3, 1, 2, 3, 0, 1, 2, 2, 0, 3, 3]\n",
    "\n",
    "Przy użyciu tradycyjnego algorytmu będziemy chcieli je porównać również dla tekstu nie zmodyfikowanego przez użytkownika, który mógł usunąć pewną linijkę lub usunąc z niektórych spacje, kolejności raczej się nie zmienia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1: [0, 3, 1, 3, 3, 1, 2, 3, 0, 1, 2, 2, 0, 3, 3]\n",
      "P2: [0, 0, 0, 3, 1, 2, 3, 0, 2, 2, 0, 1]\n",
      "Prawdopodobieństwo ciągów: 0.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def LCS(s1, s2, m, n, memo):\n",
    " \n",
    "   # Base Case\n",
    "    if m == 0 or n == 0:\n",
    "        return 0\n",
    "\n",
    "    # Already exists in the memo table\n",
    "    if memo[m][n] != -1:\n",
    "        return memo[m][n]\n",
    "\n",
    "    # Match\n",
    "    if s1[m - 1] == s2[n - 1]:\n",
    "        memo[m][n] = 1 + LCS(s1, s2, m - 1, n - 1, memo)\n",
    "        return memo[m][n]\n",
    "\n",
    "    # Do not match\n",
    "    memo[m][n] = max(LCS(s1, s2, m, n - 1, memo),\n",
    "                     LCS(s1, s2, m - 1, n, memo))\n",
    "    \n",
    "    return memo[m][n]\n",
    "\n",
    "def check_patterns(pattern_list_original, pattern_list_extracted):\n",
    "    \n",
    "    original_pattern = list(map(lambda x: str(x), pattern_list_original))\n",
    "    extracted_pattern = list(map(lambda x: str(x), pattern_list_extracted ))\n",
    "\n",
    "    p1 = \"\".join(original_pattern)\n",
    "    p2 = \"\".join(extracted_pattern)\n",
    "    \n",
    "    m = len(p1)\n",
    "    n = len(p2)\n",
    "    memo = [[-1 for _ in range(n + 1)] for _ in range(m + 1)]\n",
    "    \n",
    "    p = LCS(p1, p2, m, n, memo)\n",
    "    \n",
    "    \n",
    "    r =  p / len(original_pattern)\n",
    "    print(\"Prawdopodobieństwo ciągów:\", r)\n",
    "    \n",
    "    return r\n",
    "\n",
    "\n",
    "filename1 = \"./watermarked_code/is_prime_w1.py\"\n",
    "#modified, by removing lines and some spaces\n",
    "filename2 = \"./watermarked_code/is_prime_w2.py\" \n",
    "\n",
    "\n",
    "watermarked_code_unmodified = get_func(filename1)\n",
    "watermarked_code_modified = get_func(filename2)\n",
    "\n",
    "pattern1 = extract_multiple_inv_signs_watermark(watermarked_code_unmodified)\n",
    "pattern2 = extract_multiple_inv_signs_watermark(watermarked_code_modified)\n",
    "\n",
    "print(\"P1:\", pattern1)\n",
    "print(\"P2:\", pattern2)\n",
    "\n",
    "check_patterns(pattern1, pattern2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Inna, bardziej zaawansowana metoda steganografii\n",
    "\n",
    "Tym razem będziemy wzorować się na metodach zaprezentowanych w [3](https://arxiv.org/pdf/1302.2718). Metody, które chcielibyśmy przenieść na warunki programistyczne to:\n",
    "1. Dodawanie \"\\_\" do nazw zmiennych w odpowiednich miejscach, (zamiast zaproponowanych \"?\") ich rozmieszczenie w kodzie będzie możliwe do zakodowania pewnych informacji, ale możliwe że będzie wymagało to dodatkowej informacji, aby tak zmodyfikowane zmienne lub nazwy funkcji nie wzbudzały podejrzeń, szczegóły w referowanym pliku - metoda 1: **Missing Letter Puzzle**\n",
    "2. Nazywanie zmiennych w odpowiedni sposób - metoda 2: **Hiding Data in Wordlist**, tutaj ponownie, prawdopodobne, że wymagałoby to interwencji przez kodującego mając na uwadze pewne ściśle nałożone warunki.\n",
    "\n",
    "\n",
    "Oczywiście ze względu na strukturę kodu, wprowadzone modyfikacje do nazw musiałyby być uwzględnione globalnie a nie jedynie ad hoc. A raczej napewno wsm, bo będziemy musieli modyfikować długość zmiennej w trakcie algorytmu.\n",
    "\n",
    "Algorytm również nie działa jak to zostało opisane w tekście, prawdopodobnie wynika to z różnicami co do sposobu rozumienia pozycji. Więc zamiast porównywać z orygianlnym hasłem, należałoby porównywać z hasłem odczytanym z zwatermarkowanego kodu.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification classi_\n",
      "generated_code gener_\n",
      "left leftyf_\n",
      "middle mi__len\n",
      "model mo_eldon\n",
      "next_value next__\n",
      "result resu_tpb\n",
      "right ri__tqq\n",
      "sequence se_uence\n",
      "train_code tra_n_c\n",
      "train_labels train_\n",
      "FLAG: 0\n",
      "SEEKING:\n",
      "IDK: 11 ['classi_', 'gener_', 'leftyf_', 'mi__len', 'mo_eldon', 'next__', 'resu_tpb', 'ri__tqq', 'se_uence', 'tra_n_c', 'train_']\n",
      "MSG: LALIRATIRJA\n",
      "CLOSE ENOUGH\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# ~ Metoda 1- MLP: Missing Letter Puzzle: ? -> _, \n",
    "\n",
    "def retrieve_var_names(code, n):\n",
    "    \n",
    "    pattern = r'^\\s*([a-zA-Z_][a-zA-Z0-9_]*)\\s* ='  # Dopasowuje nazwę zmiennej przed znakiem '='\n",
    "    initizalization_vars = set()\n",
    "    \n",
    "    lines = code.splitlines()\n",
    "    for i, line in enumerate(lines):\n",
    "\n",
    "        match = re.match(pattern, line)\n",
    "        if match:\n",
    "            #print(\"--\", match.group(1))\n",
    "            #print(\"M:\", match.group())\n",
    "            initizalization_vars.add(match.group(1))\n",
    "        \n",
    "        if len(initizalization_vars) == n:\n",
    "            break\n",
    "\n",
    "    \n",
    "    \n",
    "    return sorted(list(initizalization_vars))\n",
    "\n",
    "\n",
    "def retrieve_var_names2(code, n):\n",
    "    \n",
    "    pattern = r'^\\s*([a-zA-Z_][a-zA-Z0-9_]*)\\s* ='  # Dopasowuje nazwę zmiennej przed znakiem '='\n",
    "    initizalization_vars = set()\n",
    "    \n",
    "    lines = code.splitlines()\n",
    "    for i, line in enumerate(lines):\n",
    "\n",
    "        match = re.match(pattern, line)\n",
    "        if match:\n",
    "            #print(\"--\", match.group(1))\n",
    "            #print(\"M:\", match.group())\n",
    "            if len(match.group(1)) > 1:\n",
    "                initizalization_vars.add(match.group(1))\n",
    "        \n",
    "        if len(initizalization_vars) == n:\n",
    "            break\n",
    "\n",
    "    \n",
    "    return sorted(list(initizalization_vars))\n",
    "\n",
    "\n",
    "def modify_word(word, desired_length):\n",
    "    c_n = len(word)\n",
    "    d_n = desired_length\n",
    "    m_word = \"\"\n",
    "    \n",
    "    change = {}\n",
    "    \n",
    "    if c_n == d_n:\n",
    "        m_word = word\n",
    "    elif c_n < d_n :\n",
    "        letters =  random.choices(\"abcdefghijklmnopqrstuwyz\", k=(d_n - c_n))\n",
    "        m_word = word + \"\".join(letters)\n",
    "    else:\n",
    "        m_word = word[:d_n]\n",
    "    \n",
    "    change[\"before\"] = word\n",
    "    change[\"after\"] = m_word\n",
    "\n",
    "    return change\n",
    "\n",
    "\n",
    "#SHOULD BE APPLIED TO 1 LIMITED SCOPE - FUNC, AND AT LEASTE len(KEYWORD) INITIALIZATIONS...\n",
    "\n",
    "def MLP_hide(init_vars, key):\n",
    "    flag = 0\n",
    "    changes = {}\n",
    "    \n",
    "    for i, letter in enumerate(key):\n",
    "        \n",
    "        n = ord(letter)\n",
    "        #print(\"N:\", n)\n",
    "        var = init_vars[i]\n",
    "        \n",
    "        if n < 100:\n",
    "            \n",
    "            flag = 0\n",
    "            q = n // 10\n",
    "            r = n % 10\n",
    "            \n",
    "            #print(\"-v\", var, \"-q\", q, '-r', r)\n",
    "            if q < 6:\n",
    "                l = 10 + q\n",
    "            else:\n",
    "                l = q\n",
    "            #print(\"l:\", l)\n",
    "            \n",
    "            word_change = modify_word(var, l)\n",
    "            word_before = word_change[\"before\"]\n",
    "            word_after = word_change[\"after\"]\n",
    "            #if word_before != word_after:\n",
    "            #    changes.append(word_change)            \n",
    "    \n",
    "            # x in the end is a equivalent to proposed 'hint'\n",
    "            if r == 0:\n",
    "                pos = np.random.choice(range(1, l))\n",
    "                word_after = word_after[:pos] + \"_\" + word_after[pos+1:] + \"x\"\n",
    "            elif r <= q:\n",
    "                word_after = word_after[:r] + \"_\" + word_after[r+1:]\n",
    "            else:\n",
    "                pos1 = r - q\n",
    "                if q in [6, 7, 8, 9]:\n",
    "                    pos2 = np.random.choice(range(3, l))\n",
    "                elif q in range(0, 6):\n",
    "                    pos2 = np.random.choice(range(9, l))\n",
    "                \n",
    "                if pos2 < pos1:\n",
    "                    pos2, pos1 = pos1, pos2\n",
    "                \n",
    "                word_after = word_after[:pos1] + \"_\" + word_after[pos1+1:pos2] + \"_\" + word_after[pos2+1:]        \n",
    "             \n",
    "            changes[word_before] = word_after    \n",
    "            #changes.append((word_before, word_after))\n",
    "                \n",
    "        else:\n",
    "            flag = 1 + (n % 10)\n",
    "            q = int(str(n)[0])\n",
    "            r = int(str(n)[1])\n",
    "            #print(\"-vv\", var, \"-q\", q, '-r', r)\n",
    "            l = 10 + q\n",
    "            word_change = modify_word(var, l)\n",
    "            word_before = word_change[\"before\"]\n",
    "            word_after = word_change[\"after\"]\n",
    "            #if word_before != word_after:\n",
    "            #    changes.append(word_change) \n",
    "            \n",
    "            if r == 0:\n",
    "                pos = np.random.choice(range(10, l))\n",
    "                word_after = word_after[:pos] + \"_\" + word_after[pos+1:]\n",
    "            else:\n",
    "                word_after = word_after[:r] + \"_\" + word_after[r+1:] \n",
    "                \n",
    "            changes[word_before] = word_after\n",
    "            #changes.append((word_before, word_after))\n",
    "                   \n",
    "    return changes, flag\n",
    "\n",
    "def MLP_seek(changed_vars, k):\n",
    "    msg = \"\"\n",
    "    for i, var in enumerate(changed_vars):\n",
    "        \n",
    "        if k == 0:\n",
    "            l = len(var)\n",
    "            \n",
    "            positions = []\n",
    "            start = 0\n",
    "            while True:\n",
    "                position = var.find('_', start)\n",
    "                if position == -1:\n",
    "                    break\n",
    "                positions.append(position)\n",
    "                start = position + 1\n",
    "            \n",
    "            #print(\"POSITIONS:\", positions)\n",
    "            \n",
    "            if l > 9:\n",
    "                l -= 10\n",
    "            if var[-1] == \"x\":\n",
    "                r = 0\n",
    "            elif len(positions) == 2:\n",
    "                r = 1 + positions[0]\n",
    "            else:\n",
    "                r = positions[0]\n",
    "            \n",
    "            value = l*10 + r\n",
    "        \n",
    "        else:\n",
    "            l = len(var)\n",
    "            a = k - l\n",
    "            l -= 10\n",
    "            r = var.index(\"_\")\n",
    "            if r > 9:\n",
    "                r = 0\n",
    "            value = l*100 + (r*10) + a\n",
    "            \n",
    "        char = chr(value)\n",
    "        msg += char\n",
    "    \n",
    "    return msg\n",
    "\n",
    "\n",
    "with open(\"init-code/init_long.py\", \"r\") as f:\n",
    "    code_example = f.read()\n",
    "\n",
    "\n",
    "\n",
    "key = \"LABORATORIA\"\n",
    "init_vars = retrieve_var_names2(code_example, len(key)) \n",
    "\n",
    "\n",
    "changes, flag = MLP_hide(init_vars, key)\n",
    "for change in changes:\n",
    "    print(change, changes[change])\n",
    "    \n",
    "print(\"FLAG:\", flag)\n",
    "\n",
    "print(\"SEEKING:\")\n",
    "vars = [changes[x] for x in changes]\n",
    "\n",
    "print(\"IDK:\", len(vars), vars)\n",
    "\n",
    "msg = MLP_seek(vars, flag)\n",
    "print(\"MSG:\", msg)\n",
    "\n",
    "print(\"CLOSE ENOUGH\")\n",
    "\n",
    "# TO DO - apply it to code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Połączenie zebranych metod\n",
    "\n",
    "W ramach funkcji watermarkującej, łączymy kilka wcześniej przygotowanych funkcji, dodające pewne charakterystyki do kodu. Są to:\n",
    "- **M1**: zakodowanie wybranego hasła jak ciąg bitów poprzez dodanie do każdej linijki, gdzie znak spacji = 0, znak tab = 1,\n",
    "- **M2**: dodawanie *stylu* poprzez zamianę znaków w nazwach zmiennych, np. s -> 5\n",
    "- **M3**: dodawanie zmiennej liczby znaków niewidzialnych do końca linii (rozwinięcie M1)\n",
    "- **M4**: przekształcanie zmiennych z próbą adaptacji algorytmu Missing Word Puzzle\n",
    "- **M5**: dodawanie *stylu* poprzez sortowanie importów\n",
    "\n",
    "M4 tak naprawdę wymagałaby specjalnej interwencji użytkownika, ponieważ w jego ramach mogło dojść do znacznych zmian nazw zmiennych, sprawiając że są stały się nieczytelne. Należałoby je modyfikować, tak aby oddawały sens pierwotnemu nazewnictwu:\n",
    "1. Długość zmiennej musi pozostać taka sama\n",
    "2. Znaków: `_` anie `x` (jako ostatnie znaki) nie można usuwać ani przekształcać\n",
    "\n",
    "Właśnie przez element łatwej rozpoznawalności powodujące duże pstwo zmiany nazw zmiennych, mechanizmy M2 oraz M4 będą miały mniejszą wagę niż pozostałe, trudniejsze do wykrycia sposoby watermarkowania.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER M2:\n",
      "M2 watermark found:  True\n",
      "MESSAGE: LALIRATIRJA\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_last_n_chars(line, char):\n",
    "    \"\"\"\n",
    "    gets count of ending line char sequence\n",
    "    \"\"\"\n",
    "    i = -1\n",
    "    x = 0\n",
    "    \n",
    "    while True:\n",
    "        if len(line) > x:\n",
    "            #print(f\"LS: {ord(line[i])}, i: {i}\")\n",
    "            if line[i] == char:\n",
    "                i -= 1\n",
    "                x += 1\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    return x\n",
    "\n",
    "\n",
    "# M1 and M3\n",
    "def M1_and_M3_add(code, watermark):\n",
    "    \"\"\"\n",
    "    adds multiple (M3) space-tab (M1) watermark\n",
    "    \"\"\"\n",
    "    code_lines = code.splitlines()\n",
    "    watermark_letter_list = list(watermark)\n",
    "    \n",
    "    # M3 prep\n",
    "    watermark_hash = hashlib.sha256(watermark.encode()).hexdigest()[:4]\n",
    "    hash_n = int(re.sub(r'\\D', '1', watermark_hash))\n",
    "    random.seed(hash_n)\n",
    "    \n",
    "    m1_pattern = []\n",
    "    m3_pattern = []\n",
    "    \n",
    "    watermark_binary = ' '.join([ format(ord(c), '08b') for c in watermark])\n",
    "    print(f\"--- watermark key: {watermark}, in binary format:\", watermark_binary, \"---\" )\n",
    "    \n",
    "        \n",
    "    # code-length aware-------------------\n",
    "    \n",
    "    # every n = 2 lines, so scope is n* 8 (bites) * len(watermark)\n",
    "    n = 2\n",
    "    \n",
    "    if len(code_lines) > n * 8 *len(watermark_letter_list):\n",
    "        \n",
    "        needed_bites = len(code_lines) // n\n",
    "        current_bites =  8 * len(watermark_letter_list)\n",
    "        \n",
    "        bites_to_add = needed_bites - current_bites\n",
    "        \n",
    "        m = bites_to_add // 8\n",
    "        m = m + 1\n",
    "        \n",
    "        k = m // len(watermark_letter_list)\n",
    "        r = m % len(watermark_letter_list)\n",
    "        \n",
    "        watermark_letter_list += k * watermark_letter_list\n",
    "        watermark_letter_list += watermark_letter_list[:r]\n",
    "        \n",
    "    watermark_space_tab_pattern = ['\\t' if bit == '1' else ' ' for bit in ''.join(format(ord(c), '08b') for c in watermark_letter_list)]\n",
    "    \n",
    "          \n",
    "    # -------------------\n",
    "    \n",
    "    for i in range(1, len(code_lines), n):\n",
    "        r = random.choice(range(1, 5))\n",
    "        char =  watermark_space_tab_pattern[i // n]\n",
    "        code_lines[i] += r * char\n",
    "        \n",
    "        if char == '\\t':\n",
    "            m1_pattern.append('1')\n",
    "        else:\n",
    "            m1_pattern.append('0')\n",
    "        m3_pattern.append(r)\n",
    "            \n",
    "    #print(f\"n: {len(m3_pattern)}, M3 pattern:\", m3_pattern)\n",
    "    \n",
    "    watermarked_code = '\\n'.join(code_lines)   \n",
    "    return watermarked_code, m1_pattern, m3_pattern\n",
    "\n",
    "\n",
    "def M1_and_M3_extract(code):\n",
    "    \"\"\"\n",
    "    extracts end-of-line white characters in code and returns found patterns\n",
    "    \"\"\"\n",
    "    \n",
    "    lines = code.splitlines()\n",
    "\n",
    "    m1_pattern = []\n",
    "    m3_pattern = []\n",
    "    \n",
    "    for i in range(1, len(lines)):\n",
    "        if len(lines[i]) != 0:\n",
    "            #print(\"LINE:\", i,  lines[i])\n",
    "                        \n",
    "            last_char = lines[i][-1]\n",
    "            if last_char == '\\t':\n",
    "                m1_pattern.append('1')\n",
    "                n = get_last_n_chars(lines[i], '\\t')\n",
    "                m3_pattern.append(n)\n",
    "                \n",
    "                \n",
    "            elif last_char == ' ':\n",
    "                m1_pattern.append('0')\n",
    "                n = get_last_n_chars(lines[i], ' ')\n",
    "                m3_pattern.append(n)\n",
    "\n",
    "    watermark_text = ''\n",
    "    for i in range(0, len(m1_pattern), 8):\n",
    "        byte = ''.join(m1_pattern[i:(i + 8)])\n",
    "        #print(\"BYTE:\", byte)\n",
    "        if len(byte) == 8:\n",
    "            watermark_text += chr(int(byte, 2))\n",
    "\n",
    "    if watermark_text:\n",
    "        print(\"--- pattern found:\", watermark_text)\n",
    "    \n",
    "    return watermark_text, m1_pattern, m3_pattern\n",
    "\n",
    "\n",
    "# M2\n",
    "def M2_add(code, watermark):\n",
    "    \"\"\"\n",
    "    adds style - similar characters to code\n",
    "    \"\"\"\n",
    "    \n",
    "    SIMILAR_CHARS = {\n",
    "       # 'a': '@',\n",
    "        'e': '3',\n",
    "        'i': '1',\n",
    "        'o': '0',\n",
    "        'l': '1',\n",
    "        's': '5',\n",
    "        't': '7'\n",
    "    } \n",
    "    BUILTINS = dir(__builtins__)\n",
    "    \n",
    "    watermark_hash = hashlib.sha256(watermark.encode()).hexdigest()[:4]\n",
    "    hash_numbers = re.sub(r'\\D', '1', watermark_hash) # only digits\n",
    "    hash_n = sum([int(nr) for nr in list(hash_numbers)])%10\n",
    "    \n",
    "    def modify_variable(name):\n",
    "        if name in keyword.kwlist or name in BUILTINS:\n",
    "            return name\n",
    "        \n",
    "        modified_name = name[0]\n",
    "        for i, char in enumerate(name[1:], 1):\n",
    "            if char.lower() in SIMILAR_CHARS and i % hash_n == 0:\n",
    "                modified_name += SIMILAR_CHARS[char.lower()]\n",
    "            else:\n",
    "                modified_name += char\n",
    "        return modified_name\n",
    "    \n",
    "    all_vars = retrieve_var_names(code, -1)\n",
    "    to_modify = {}\n",
    "    \n",
    "    def replace_from_dict(match):\n",
    "        return to_modify[match.group(0)] \n",
    "    \n",
    "    if len(all_vars) != 0:\n",
    "        for var in all_vars: \n",
    "            modified_var = modify_variable(var)\n",
    "            to_modify[var] = modified_var\n",
    "            \n",
    "         \n",
    "    pattern = r'\\b(' + '|'.join(re.escape(key) for key in to_modify) + r')\\b'\n",
    "    \n",
    "    lines = code.splitlines()\n",
    "    updated_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if not (line.startswith(\"import\") or line.startswith(\"from\")):\n",
    "            \n",
    "            updated_line = re.sub(pattern, replace_from_dict, line) \n",
    "            updated_lines.append(updated_line)\n",
    "        else:\n",
    "            updated_lines.append(line)\n",
    "    \n",
    "    return '\\n'.join(updated_lines)\n",
    "\n",
    "\n",
    "def M2_extract(code, watermark):\n",
    "    \"\"\"\n",
    "    checks whether in code there are present signs of our *style*\n",
    "    \"\"\"\n",
    "\n",
    "    watermark_hash = hashlib.sha256(watermark.encode()).hexdigest()[:4]\n",
    "    hash_numbers = re.sub(r'\\D', '1', watermark_hash) \n",
    "    hash_n = sum([int(nr) for nr in list(hash_numbers)])%10\n",
    "    \n",
    "    def check_variable(name):\n",
    "\n",
    "        original_name = name[0]\n",
    "        for i, char in enumerate(name[1:], 1):\n",
    "            if char in SIMILAR_CHARS.values() and i % hash_n == 0:\n",
    "                original_char = next((k for k, v in SIMILAR_CHARS.items() if v == char), None)\n",
    "                if original_char:\n",
    "                    original_name += original_char\n",
    "                else:\n",
    "                    return False\n",
    "            else:\n",
    "                original_name += char\n",
    "        \n",
    "        return original_name != name\n",
    "\n",
    "\n",
    "    variable_pattern = re.compile(r'\\b([a-zA-Z_][a-zA-Z0-9_]*)\\b =')\n",
    "        \n",
    "    for match in variable_pattern.findall(code):\n",
    "        if check_variable(match):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "# M5\n",
    "def M5_add(code, watermark):\n",
    "    \"\"\"\n",
    "    adds style - sorts imports statements in code\n",
    "    \"\"\"\n",
    "    \n",
    "    lines = code.splitlines()\n",
    "    \n",
    "    imports = [line for line in lines if line.startswith(\"import\") or line.startswith(\"from\")]\n",
    "    other_lines = [line for line in lines if not (line.startswith(\"import\") or line.startswith(\"from\"))]\n",
    "    \n",
    "    # hash\n",
    "    watermark_hash = hashlib.sha256(watermark.encode()).hexdigest()\n",
    "    # sort\n",
    "    sorted_imports = sorted(imports, key=lambda x: hashlib.sha256((x + watermark_hash).encode()).hexdigest())\n",
    "    return '\\n'.join(sorted_imports + other_lines)\n",
    "\n",
    "\n",
    "# yes, it takes both files: original and for verification, we could just compare imports whether they equal sorted import list,\n",
    "# but user could add another import, so by utilizng comparison to original file we have 2 in 1: we know for sure that our code has sorted imports, and we exclude their changes \n",
    "def M5_extract_and_compare(filename_code_original, filename_code_to_verify):\n",
    "    \"\"\"\n",
    "    checks whether imports in verified file are in the same seqeunce as in original, watermarked code\n",
    "    \"\"\"\n",
    "    code_original = get_func(filename_code_original)\n",
    "    code_to_verify = get_func(filename_code_to_verify)\n",
    "    \n",
    "    lines_code_original = code_original.splitlines()\n",
    "    lines_code_to_verify = code_to_verify.splitlines()\n",
    "    \n",
    "    imports_original = [line for line in lines_code_original if line.startswith(\"import\") or line.startswith(\"from\")]\n",
    "    imports_to_verify = [line for line in lines_code_to_verify if line.startswith(\"import\") or line.startswith(\"from\")]\n",
    "    \n",
    "    #filter import to verify\n",
    "    imports_to_verify_filter = list(filter(lambda x: x in imports_original, imports_to_verify))\n",
    "    \n",
    "    #print(\"IMPORT ORIGINAL:\", imports_original)\n",
    "    #print(\"IMPORT TO VERIFY:\", imports_to_verify_filter)\n",
    "    \n",
    "    return imports_original == imports_to_verify_filter\n",
    "\n",
    "\n",
    "# M4\n",
    "def M4_add(code, watermark):\n",
    "    \"\"\"\n",
    "    add watermark through adaptation of Missing Word Puzzle algorithm\n",
    "    \"\"\"\n",
    "\n",
    "    all_vars = retrieve_var_names2(code, len(watermark))\n",
    "    \n",
    "    if len(all_vars) < len(watermark):\n",
    "        print(\"code is too small ..............\")\n",
    "        return code, -1\n",
    "    else:\n",
    "        changes_in_vars, key = MLP_hide(all_vars, watermark)\n",
    "        \n",
    "        #print(\"ADD changes in vars\", len(changes_in_vars.keys()), changes_in_vars)\n",
    "    \n",
    "        def replace_from_dict(match):\n",
    "            return changes_in_vars[match.group(0)] \n",
    "                       \n",
    "     \n",
    "        pattern = r'\\b(' + '|'.join(re.escape(key) for key in changes_in_vars) + r')\\b'       \n",
    "        lines = code.splitlines()\n",
    "        updated_lines = []\n",
    "        \n",
    "    \n",
    "        for line in lines:\n",
    "            if not (line.startswith(\"import\") or line.startswith(\"from\")):\n",
    "                \n",
    "                #print(\"LINE:\", line)\n",
    "                updated_line = re.sub(pattern, replace_from_dict, line) \n",
    "                #print(\"UPDATED LINE:\", updated_line)\n",
    "                \n",
    "                updated_lines.append(updated_line)\n",
    "            else:\n",
    "                updated_lines.append(line)\n",
    "        \n",
    "        return '\\n'.join(updated_lines), key    \n",
    "    \n",
    "\n",
    "def M4_extract(code, watermark, key):\n",
    "    \"\"\"\n",
    "    extract message from\n",
    "    \"\"\"\n",
    "    all_vars = retrieve_var_names2(code, len(watermark))\n",
    "    #print(\"ALL VARS EXTRACT:\",len(all_vars), all_vars)\n",
    "    watermark = MLP_seek(all_vars, key)\n",
    "    \n",
    "    return watermark\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# sanity check\n",
    "\n",
    "with open(\"init-code/init_long.py\", \"r\") as f:\n",
    "    code_example = f.read()\n",
    "\n",
    "WATERMARK = \"LABORATORIA\"\n",
    "\n",
    "'''\n",
    "code = M2_add(code_example, WATERMARK)\n",
    "p_m2 = M2_extract(code, WATERMARK)\n",
    "\n",
    "#print(\"CODECODECODE:\")\n",
    "#print(code)\n",
    "print(\"M2\")\n",
    "print(p_m2)\n",
    "\n",
    "\n",
    "watermarked_code, original_m1_pattern, original_m3_pattern = M1_and_M3_add(code, WATERMARK)\n",
    "watermark_text, watermarked_code_m1_pattern, watermarked_code_m3_pattern = M1_and_M3_extract(watermarked_code)\n",
    "\n",
    "print()\n",
    "print(\"M1\")\n",
    "print(original_m1_pattern)\n",
    "print(watermarked_code_m1_pattern)\n",
    "print()\n",
    "print(\"M3\")\n",
    "print(original_m3_pattern)\n",
    "print(watermarked_code_m3_pattern)\n",
    "print()\n",
    "\n",
    "p_m1 = check_patterns(original_m1_pattern, watermarked_code_m1_pattern)\n",
    "p_m3 = check_patterns(original_m3_pattern, watermarked_code_m3_pattern)\n",
    "\n",
    "'''\n",
    "\n",
    "example_code = \"\"\"\n",
    "\n",
    "def calculate_area(length, width):\n",
    "    result = length * width\n",
    "    return result\n",
    "\n",
    "def greet_user(name):\n",
    "    greeting = f\"Hello, {name}!\"\n",
    "    print(greeting)\n",
    "\n",
    "def compute_sum(numbers):\n",
    "    total = 0\n",
    "    print(\"--\")\n",
    "    for num in numbers:\n",
    "        total += num\n",
    "    print(total)\n",
    "    return total\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "code_after_m2 = M2_add(code_example, WATERMARK)\n",
    "print(\"AFTER M2:\")\n",
    "#print(code_after_m2)\n",
    "m2 = M2_extract(code_after_m2, WATERMARK)\n",
    "print(\"M2 watermark found: \", m2)\n",
    "\n",
    "\n",
    "code, key = M4_add(code_example, WATERMARK)\n",
    "message = M4_extract(code, WATERMARK, key)\n",
    "\n",
    "print(\"MESSAGE:\", message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "________________________________________\n",
      "=== WATERMARKING CODE ===\n",
      "\n",
      "= M5 applied\n",
      "= M2 applied\n",
      "--- M4 KEY is: 0\n",
      "= M4 applied\n",
      "--- watermark key: LABORATORIA, in binary format: 01001100 01000001 01000010 01001111 01010010 01000001 01010100 01001111 01010010 01001001 01000001 ---\n",
      "= M1 and M3 applied\n",
      "\n",
      "=== Watermark added and saved to file: watermarked_code/init_long.py ===\n",
      "________________________________________\n",
      "\n",
      "=== ESTIMATING SIMILARITY MEASURE ===\n",
      "\n",
      "--- pattern found: LABORATORIALAB\n",
      "Text extracted from file: watermarked_code/init_long.py is LABORATORIALAB\n",
      "M4 PATTERN: LALIRATIRJA\n",
      "--- pattern found: LABORATORIALAB\n",
      "Text extracted from file: watermarked_code/init_long.py is LABORATORIALAB\n",
      "M4 PATTERN: LALIRATIRJA\n",
      "\n",
      "m1:\n",
      "Prawdopodobieństwo ciągów: 1.0\n",
      "m3:\n",
      "Prawdopodobieństwo ciągów: 1.0\n",
      "m4:\n",
      "Prawdopodobieństwo ciągów: 1.0\n",
      "m2:\n",
      "found m2 wattermark: True\n",
      "m5:\n",
      "found m5 wattermark: True\n",
      "\n",
      "\n",
      "Computed score of similiarity: 100.0 / 100\n",
      "________________________________________\n",
      "\n",
      "!!! FINAL SCORE: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# I/O =============\n",
    "\n",
    "def get_code_from_file(filepath):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        code_example = f.read()\n",
    "\n",
    "    return code_example\n",
    "\n",
    "def save_code_to_file(filepath, code):\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(code)\n",
    "\n",
    "# I/O =============\n",
    "\n",
    "def watermark_code(filename, dest_filename, watermark):\n",
    "    \n",
    "    print(\"\\n________________________________________\")\n",
    "    print(\"=== WATERMARKING CODE ===\\n\")\n",
    "    \n",
    "    code = get_code_from_file(filename)\n",
    "    \n",
    "    # add M5\n",
    "    code = M5_add(code, watermark)\n",
    "    print(\"= M5 applied\")\n",
    "    \n",
    "    # add M2\n",
    "    code = M2_add(code, watermark)    \n",
    "    print(\"= M2 applied\")\n",
    "    \n",
    "    \n",
    "    # add M4\n",
    "    code, m4_key = M4_add(code, watermark) \n",
    "    \n",
    "    print(\"--- M4 KEY is:\", m4_key)\n",
    "    print(\"= M4 applied\")\n",
    "    \n",
    "    # add M1 and M3\n",
    "    watermarked_code, _, _ = M1_and_M3_add(code, watermark)\n",
    "    print(\"= M1 and M3 applied\")\n",
    "    \n",
    "    save_code_to_file(dest_filename, watermarked_code)\n",
    "    \n",
    "    print(f\"\\n=== Watermark added and saved to file: {dest_filename} ===\")\n",
    "    print(\"________________________________________\\n\")\n",
    "       \n",
    "    return m4_key\n",
    "\n",
    "\n",
    "def extract_watermark(filename, watermark, m4_key):\n",
    "    \n",
    "    code = get_code_from_file(filename)\n",
    "    \n",
    "    # extract M1 and M3\n",
    "    watermark_text, m1_pattern, m3_pattern = M1_and_M3_extract(code)\n",
    "    \n",
    "    print(f\"Text extracted from file: {filename} is {watermark_text}\")\n",
    "    \n",
    "    # extract M2\n",
    "    watermark_m2 = M2_extract(code, watermark)\n",
    "    \n",
    "    # extract M4\n",
    "    m4_pattern = ''\n",
    "    if m4_key != -1:\n",
    "        m4_pattern = M4_extract(code, watermark, m4_key)\n",
    "        # transform to binary\n",
    "        print(\"M4 PATTERN:\", m4_pattern)\n",
    "        m4_pattern = ' '.join([ format(ord(c), '08b') for c in m4_pattern])\n",
    "        m4_pattern = list(m4_pattern)\n",
    "    # extract M5 - NOT HERE\n",
    "    \n",
    "    return m1_pattern, watermark_m2, m3_pattern, m4_pattern\n",
    "\n",
    "\n",
    "def measure_presence_of_watermark(filename_code_original, filename_code_to_verify, m4_key, watermark):\n",
    "    print(\"=== ESTIMATING SIMILARITY MEASURE ===\\n\")\n",
    "    \n",
    "    score = 0\n",
    "    max_score = 100\n",
    "    \n",
    "    original_m1_pattern, p_m2, original_m3_pattern, original_m4_pattern = extract_watermark(filename_code_original, watermark, m4_key)\n",
    "    to_verify_m1_pattern, p_m2, to_verify_m3_pattern, to_verify_m4_pattern = extract_watermark(filename_code_to_verify, watermark, m4_key)\n",
    "    \n",
    "    #print(\"-------------\")\n",
    "    #print(\"M4 original: \", original_m4_pattern)\n",
    "    #print(\"M4 to verify:\", to_verify_m4_pattern)\n",
    "    #print(\"-------------\")\n",
    "    \n",
    "    p_m5 = M5_extract_and_compare(filename_code_original, filename_code_to_verify)\n",
    "    \n",
    "    #based on lcs\n",
    "    print(\"\\nm1:\")\n",
    "    p_m1 = check_patterns(original_m1_pattern, to_verify_m1_pattern)\n",
    "    print(\"m3:\")\n",
    "    p_m3 = check_patterns(original_m3_pattern, to_verify_m3_pattern)\n",
    "    print(\"m4:\")\n",
    "    p_m4 = check_patterns(original_m4_pattern, to_verify_m4_pattern)\n",
    "    print(\"m2:\")\n",
    "    print(\"found m2 wattermark:\", p_m2)\n",
    "    print(\"m5:\")\n",
    "    print(\"found m5 wattermark:\", p_m5)\n",
    "    print()\n",
    "    \n",
    "    if m4_key == -1:\n",
    "        p_m4 = 0\n",
    "    \n",
    "    weights_of_m = [0.3, 0.08, 0.42,  0.1, 0.1]\n",
    "    ps = [p_m1, p_m2, p_m3, p_m4, p_m5]\n",
    "    \n",
    "    for p, w in zip(ps, weights_of_m):\n",
    "        score += p * w \n",
    "    \n",
    "    score *= 100\n",
    "    \n",
    "    print(f\"\\nComputed score of similiarity: {score} / {max_score}\")\n",
    "    print(\"________________________________________\\n\")\n",
    "    \n",
    "    return score / max_score\n",
    "\n",
    "\n",
    "\n",
    "############################################################################\n",
    "# MAIN MAIN MAIN MAIN MAIN MAIN MAIN MAIN MAIN MAIN MAIN MAIN MAIN MAIN MAIN\n",
    "\n",
    "filename_code_to_watermark = \"init-code/init_long.py\"\n",
    "filename_code_to_extract_watermark = \"watermarked_code/init_long.py\"\n",
    "WATERMARK = \"LABORATORIA\"\n",
    "\n",
    "m4_key = watermark_code(filename_code_to_watermark, filename_code_to_extract_watermark, WATERMARK)\n",
    "\n",
    "# PORÓWNUJEMY TEN SAM KOD WIĘC POWINNO BYĆ > 90 idk\n",
    "score = measure_presence_of_watermark(filename_code_to_extract_watermark, filename_code_to_extract_watermark, m4_key, WATERMARK)\n",
    "\n",
    "print(f\"!!! FINAL SCORE: {score}\")\n",
    "\n",
    "\n",
    "# MAIN MAIN MAIN MAIN MAIN MAIN MAIN MAIN MAIN MAIN MAIN MAIN MAIN MAIN MAIN\n",
    "############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ Metoda 2: Hiding Data in Wordlist\n",
    "\n",
    "# aborted because so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testy nieparametryczne, które rozważaliśmy, oraz dlaczego są nieodpowiednie:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Test Wilcoxona (Wilcoxon Signed-Rank Test)**\n",
    "\n",
    "- **Opis**: Test Wilcoxona porównuje medianę różnic między dwiema zależnymi próbami. Używa rang różnic, a nie samych różnic, co czyni go odpornym na wpływ ekstremalnych wartości.\n",
    "  \n",
    "- **Dlaczego nie pasuje?**  \n",
    "  W przypadku naszych danych test Wilcoxona działa na rangach różnic, co oznacza, że wielkość procentowych różnic nie wpływa bezpośrednio na wynik. Ponieważ różnice są zawsze spadkowe w naszym przypadku (przed modyfikacją watermark zawsze wynosi 100%), test może nie być wystarczająco wrażliwy na istotne zmiany w wielkości różnic procentowych.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Test Znaków (Sign Test)**\n",
    "\n",
    "- **Opis**: Test Znaków analizuje, czy liczba pozytywnych różnic jest istotnie różna od liczby negatywnych różnic. Ignoruje jednak wielkość tych różnic.\n",
    "\n",
    "- **Dlaczego nie pasuje?**  \n",
    "  Test Znaków nie uwzględnia wielkości różnic, a jedynie ich kierunek (czy różnica jest dodatnia czy ujemna). W naszym przypadku wszystkie różnice są ujemne, co prowadzi do maksymalnego wyniku testu i braku różnic w p-wartościach, niezależnie od wielkości różnic procentowych.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Test McNemara**\n",
    "\n",
    "- **Opis**: Test McNemara jest używany do analizy danych binarnych dla prób zależnych, np. gdy chcemy sprawdzić, czy proporcja sukcesów przed i po interwencji różni się istotnie.\n",
    "\n",
    "- **Dlaczego nie pasuje?**  \n",
    "  Nasze dane są procentowe, a nie binarne. Test McNemara wymaga konwersji procentów na dane binarne (np. sukces/porażka przy ustalonej granicy), co prowadzi do utraty informacji o wielkości zmian i zbyt dużego uproszczenia danych.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Test Manna-Whitneya (Mann-Whitney U Test)**\n",
    "\n",
    "- **Opis**: Test Manna-Whitneya porównuje mediany dwóch niezależnych grup. Jest to nieparametryczny odpowiednik testu t-Studenta dla prób niezależnych.\n",
    "\n",
    "- **Dlaczego nie pasuje?**  \n",
    "  Nasze dane pochodzą z **prób zależnych** (przed i po modyfikacji tego samego kodu), więc test Manna-Whitneya nie jest odpowiedni. Ponadto test ten porównuje mediany dwóch grup, a nie różnice między nimi.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Test Permutacyjny**\n",
    "\n",
    "- **Opis**: Test permutacyjny polega na wielokrotnym losowym przekształcaniu danych w celu stworzenia rozkładu statystyki testowej, na podstawie którego można obliczyć p-wartość.\n",
    "\n",
    "- **Dlaczego nie pasuje?**  \n",
    "  W naszym przypadku test permutacyjny również może nie być odpowiedni, ponieważ wszystkie różnice są w tym samym kierunku (ujemne). To prowadzi do bardzo małych p-wartości, które są niemal stałe, niezależnie od wielkości zmian procentowych.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Test Kolmogorowa-Smirnova (K-S Test)**\n",
    "\n",
    "- **Opis**: Test K-S sprawdza, czy dwa zbiory danych pochodzą z tego samego rozkładu. Może być stosowany do porównywania dwóch rozkładów empirycznych.\n",
    "\n",
    "- **Dlaczego nie pasuje?**  \n",
    "  Próbka przed modyfikacją zawsze wynosi 100%, co prowadzi do skrajnie jednostajnego rozkładu. Nie ma sensu porównywać tego z próbką po modyfikacji, ponieważ różnica między rozkładami będzie trywialna i wynika z charakteru danych, a nie z ich statystycznej zmienności.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Test U (Mann-Whitney U Test dla różnic)**\n",
    "\n",
    "- **Opis**: Próba wykorzystania testu U do analizy różnic w zależnych próbach poprzez sztuczne rozdzielenie różnic na niezależne grupy.\n",
    "\n",
    "- **Dlaczego nie pasuje?**  \n",
    "  Test U wymaga niezależnych grup, a różnice w naszych danych są zależne (pochodzą z tych samych par). Przekształcanie różnic na dwie niezależne grupy jest błędne z punktu widzenia założeń testu.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m     plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[0;32m     41\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 43\u001b[0m \u001b[43mperform_stats\u001b[49m(differences)    \n",
      "Cell \u001b[1;32mIn[18], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m     plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[0;32m     41\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 43\u001b[0m \u001b[43mperform_stats\u001b[49m(differences)    \n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1697\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:634\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1112\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1090\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:494\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2185\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2182\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2184\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2185\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2187\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2190\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2254\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2251\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[0;32m   2252\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[1;32m-> 2254\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2255\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m   2257\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "before_modification = np.array([100, 100, 100, 100, 100, 100, 100, 100, 100, 100])\n",
    "after_modification = np.array([95, 85, 90, 92, 88, 93, 89, 87, 90, 88])\n",
    "\n",
    "differences = before_modification - after_modification\n",
    "\n",
    "def perform_stats(diff):\n",
    "\n",
    "    # Model Bayesowski\n",
    "    with pm.Model() as model:\n",
    "        # Priorytety\n",
    "        mu = pm.Normal(\"mu\", mu=0, sigma=10)\n",
    "        sigma = pm.HalfNormal(\"sigma\", sigma=10)\n",
    "\n",
    "        # Rozkład różnic\n",
    "        likelihood = pm.Normal(\"likelihood\", mu=mu, sigma=sigma, observed=diff)\n",
    "        trace = pm.sample(2000, return_inferencedata=True)\n",
    "\n",
    "    # posteriori\n",
    "    rope_min, rope_max = 0, 10\n",
    "    mu_samples = trace.posterior[\"mu\"].values.flatten()\n",
    "\n",
    "    # ROPE\n",
    "    within_rope = np.mean((mu_samples >= rope_min) & (mu_samples <= rope_max))\n",
    "    outside_rope = 1 - within_rope\n",
    "\n",
    "    print(f\"Prawdopodobieństwo, że zmiana mieści się w ROPE (0, 10): {within_rope:.2%}\")\n",
    "    print(f\"Prawdopodobieństwo, że zmiana jest istotna: {outside_rope:.2%}\")\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.hist(mu_samples, bins=30, density=True, alpha=0.7, color=\"skyblue\", label=\"Posteriori dla mu\")\n",
    "    plt.axvline(rope_min, color=\"red\", linestyle=\"--\", label=\"ROPE Min (0%)\")\n",
    "    plt.axvline(rope_max, color=\"red\", linestyle=\"--\", label=\"ROPE Max (10%)\")\n",
    "    plt.title(\"Rozkład posteriori dla średniej różnicy (mu)\")\n",
    "    plt.xlabel(\"Średnia różnica (mu)\")\n",
    "    plt.ylabel(\"Gęstość\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "perform_stats(differences)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zaproponowany test statystyczny\n",
    "\n",
    "Kod realizuje **podejście Bayesowskie** do analizy różnic procentowych, przy czym wykorzystuje narzędzie ROPE (Region of Practical Equivalence), aby ocenić, czy zmiana różnic (np. w watermarku) jest statystycznie i praktycznie istotna.\n",
    "\n",
    "#### 1. **Bayesowski test hipotez**:\n",
    "   - Kod realizuje analizę **Bayesowską**, która różni się od testów klasycznych (np. test t-Studenta, Wilcoxona):\n",
    "     - **Nie zakłada hipotezy zerowej** (że nie ma efektu) ani alternatywnej.\n",
    "     - Zamiast tego estymuje rozkład posteriori dla interesujących nas parametrów (\\( \\mu \\), \\( \\sigma \\)).\n",
    "   - Wynik analizy ROPE:\n",
    "     - Jeśli większość posteriori mieści się w przedziale ROPE, możemy powiedzieć, że zmiana jest nieistotna **w sensie praktycznym**.\n",
    "     - Jeśli wartości są poza ROPE, zmiana jest praktycznie istotna.\n",
    "\n",
    "#### 2. **Nieparametryczne podejście**:\n",
    "   - Bayesowskie modele pozwalają elastycznie dopasować rozkład posteriori bez założeń o normalności danych (choć w tym przykładzie użyto rozkładu normalnego dla uproszczenia).\n",
    "\n",
    "#### 3. **Test istotności dla różnic (poprzez ROPE)**:\n",
    "   - Zamiast sprawdzać tylko, czy różnice są statystycznie istotne (jak w klasycznych testach p-wartości), ten test bada również **praktyczną istotność**.\n",
    "   - Pozwala to włączyć wiedzę ekspercką (np. \\( 10\\% \\) jako akceptowalny spadek) do procesu decyzyjnego.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "#### Watermarkowanie\n",
    "- watermark z dokumentu \n",
    "- engine do watermarkowania (priorytet)\n",
    "- engine do oceny watermarku\n",
    "\n",
    "#### Badanie zmian\n",
    "- przygotowanie datasetu(oraz kodu do uruchomienia wszystkiego)\n",
    "- uzycie statystyki\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watermark_code(filename):\n",
    "    with open(f'dataset/basic_code/{filename}', 'rb') as source_file:\n",
    "        content = source_file.read()\n",
    "    with open(f'dataset/code_after_watermark/{filename}', 'wb') as dest_file:\n",
    "        dest_file.write(content)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_watermark(filename):\n",
    "    return 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores before modification:\n",
      "1.py: 80%\n",
      "2.py: 80%\n",
      "3.py: 80%\n",
      "4.py: 80%\n",
      "5.py: 80%\n",
      "6.py: 80%\n",
      "7.py: 80%\n",
      "8.py: 80%\n",
      "9.py: 80%\n",
      "10.py: 80%\n",
      "11.py: 80%\n",
      "12.py: 80%\n",
      "13.py: 80%\n",
      "14.py: 80%\n",
      "15.py: 80%\n",
      "16.py: 80%\n",
      "17.py: 80%\n",
      "18.py: 80%\n",
      "19.py: 80%\n",
      "20.py: 80%\n",
      "21.py: 80%\n",
      "22.py: 80%\n",
      "23.py: 80%\n",
      "24.py: 80%\n",
      "25.py: 80%\n",
      "26.py: 80%\n",
      "27.py: 80%\n",
      "28.py: 80%\n",
      "29.py: 80%\n",
      "30.py: 80%\n",
      "\n",
      "Scores after modification:\n",
      "dataset/code_after_change/1.py: No file found%\n",
      "dataset/code_after_change/2.py: No file found%\n",
      "dataset/code_after_change/3.py: No file found%\n",
      "dataset/code_after_change/4.py: No file found%\n",
      "dataset/code_after_change/5.py: No file found%\n",
      "dataset/code_after_change/6.py: No file found%\n",
      "dataset/code_after_change/7.py: No file found%\n",
      "dataset/code_after_change/8.py: No file found%\n",
      "dataset/code_after_change/9.py: No file found%\n",
      "dataset/code_after_change/10.py: No file found%\n",
      "dataset/code_after_change/11.py: No file found%\n",
      "dataset/code_after_change/12.py: No file found%\n",
      "dataset/code_after_change/13.py: No file found%\n",
      "dataset/code_after_change/14.py: No file found%\n",
      "dataset/code_after_change/15.py: No file found%\n",
      "dataset/code_after_change/16.py: No file found%\n",
      "dataset/code_after_change/17.py: No file found%\n",
      "dataset/code_after_change/18.py: No file found%\n",
      "dataset/code_after_change/19.py: No file found%\n",
      "dataset/code_after_change/20.py: No file found%\n",
      "dataset/code_after_change/21.py: No file found%\n",
      "dataset/code_after_change/22.py: No file found%\n",
      "dataset/code_after_change/23.py: No file found%\n",
      "dataset/code_after_change/24.py: No file found%\n",
      "dataset/code_after_change/25.py: No file found%\n",
      "dataset/code_after_change/26.py: No file found%\n",
      "dataset/code_after_change/27.py: No file found%\n",
      "dataset/code_after_change/28.py: No file found%\n",
      "dataset/code_after_change/29.py: No file found%\n",
      "dataset/code_after_change/30.py: No file found%\n",
      "Nie można obliczyć różnic - różna liczba wyników przed i po modyfikacji.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def watermark_and_score(files):\n",
    "    before_modification = []\n",
    "    after_modification = []\n",
    "\n",
    "    for file in files:\n",
    "        watermarked_file = f\"dataset/code_after_watermark/{file}\"\n",
    "\n",
    "        watermark_code(file)\n",
    "\n",
    "        before_score = score_watermark(watermarked_file)\n",
    "        before_modification.append((file, before_score))\n",
    "\n",
    "        modified_file = f\"dataset/code_after_change/{file}\"\n",
    "        if os.path.exists(modified_file):\n",
    "            after_score = score_watermark(modified_file)\n",
    "            after_modification.append((modified_file, after_score))\n",
    "        else:\n",
    "            after_modification.append((modified_file, None))\n",
    "\n",
    "    return before_modification, after_modification\n",
    "\n",
    "python_files = [f\"{i}.py\" for i in range(1, 31)]\n",
    "\n",
    "before_modification, after_modification = watermark_and_score(python_files)\n",
    "\n",
    "print(\"Scores before modification:\")\n",
    "before_scores = []\n",
    "after_scores = []\n",
    "for file, score in before_modification:\n",
    "    print(f\"{file}: {score}%\")\n",
    "    before_scores.append(score)\n",
    "\n",
    "print(\"\\nScores after modification:\")\n",
    "for file, score in after_modification:\n",
    "    print(f\"{file}: {score if score is not None else 'No file found'}%\")\n",
    "    if score is not None:\n",
    "        after_scores.append(score)\n",
    "if len(before_scores) == len(after_scores):\n",
    "    diff = np.array(before_scores) - np.array(after_scores)\n",
    "    perform_stats(diff)\n",
    "else:\n",
    "    print(\"Nie można obliczyć różnic - różna liczba wyników przed i po modyfikacji.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

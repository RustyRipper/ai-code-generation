{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Znakowanie i identyfikacja kodu wygenerowanego przez AI\n",
    "\n",
    "Temat automatycznej generacji kodu źródłowego przez Sztuczną Inteliencję (AI) jest obszerny i obejmuje różne techniki, modele oraz zastosowania. Przedmiotem naszego zainteresowania na kursie jest natomiast znalezienie sposobu na zrozumienie czy popularne generatory kodu (i ogólnego użycia) tworzą go w specyficzny dla siebie sposób, i jak tak to jaki. Chcemy odpowiedzieć na pytanie czy w dostarczonym kodzie można odnaleźć pewne statystyczne wzorce - czyli, czy AI posiada swój styl mogący go później zidentyfikować jako autora - podobnie do programistów.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naszą pierwszą czynnością było wygenerowanie kilku prostych matematycznych funkcji i algorytmów w języku Python przy użyciu ChatGPT. Już na pierwszy rzut okna dało się zauważyć pewne elementy, które mogłyby odbiegać od *normy*:\n",
    "- kod nie korzysta możliwości Pythona co do pisania zwięzłych i bardziej złożonych struktur syntaktycznych\n",
    "- przy każdej operacji pojawia się komentarz zaczynający się od wielkiej litery, a zmienne wykorzystywane mają dokładnie taką nazwę jak w komentarzu\n",
    "\n",
    "Celem jest znalezienie **statystycznego** potwierdzenia naszej intuicji, oraz znalezienie **ukrytych artefaktów** o ile istnieją - za pomocą różnych metod i narzędzie programistycznych.\n",
    "\n",
    "Zadanie detekcji, czy dany fragement kodu został napisany przez AI okazał się niezbyt dobrze opisanym w literaturze tematem, a przynajmniej takie odnieślismy wrażenie. Większość artykułów dotyczyło danych w postaci **tekstowej**. Kod oczywiście również jest zapisany w postaci tekstowej, jednak języki programowania ze względu na swoje przeznaczenie różnią się w aspektach gramatycznych i składniowych, które potrafiły być czynnikiem decydującym o decyzji czy badany tekst jest dziełem człowieka czy AI.\n",
    "Wyżej wymienione przypuszczenia przykuły też uwagę innych badaczy [1](https://arxiv.org/abs/2405.16133), którzy również zwrócili uwagę na dysproporcję w dokumentacji wykrywania wygenerowanych przez AI fragmentów kodu a tekstu i niedostępności datasetów - co było trochę oczekiwane, ponieważ dopiero od w miare niedługiego okresu, rozwiązania AI stały się użytecznym narzędziem a zarazem problemem.\n",
    "\n",
    "W swoim artykule zaprezentowali metodę wykrywania polegającą na porównaniu przepisywania przez AI kodu przygotowanego przez 1. człowieka i 2. ai. \n",
    "\n",
    "![llm rewriting](./assets/llmrewriting.png)",
    "\n",
    "Dzięki tej obserwacji przygotowali dataset z sztucznie wygenerowanymi funkcjami, z którego możemy skorzystać. Jednak zdecydowali się nauczyć model, a my chcemy deterministycznie znaleźć te różnice.\n",
    "\n",
    "W innym znalezionym badaniu [2] [https://ieeexplore.ieee.org/document/9674263/], badacze zdecydowali się stworzyć algorytm heurystyczny, który uwzględniał analizę programów z repozytoriów.\n",
    "\n",
    "![heurystyka](./assets/heurystyka.png)",
    "\n",
    "Na jego podobieństwo zbudowaliśmy własny algorytm heurystyczny, który mimo swojej prostoty i małej próbki danych potrafił wskazać na pochodzenie syntetyczne lub nie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Analysis for code_samples/ai/binary_search.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/bubble_sort.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/factorial.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/fib.py ===\n",
      "'AI Generated Probability (%): 88.89\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/is_prime.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/palindrome.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/binary_search.py ===\n",
      "'AI Generated Probability (%): 66.67\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/bubble_sort.py ===\n",
      "'AI Generated Probability (%): 44.44\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/factorial.py ===\n",
      "'AI Generated Probability (%): 33.33\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/fib.py ===\n",
      "'AI Generated Probability (%): 44.44\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/is_prime.py ===\n",
      "'AI Generated Probability (%): 44.44\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/palindrome.py ===\n",
      "'AI Generated Probability (%): 33.33\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def analyze_code(code, filename):\n",
    "    results = {\"Filename\": filename}\n",
    "\n",
    "    # Keyword Distribution\n",
    "    keywords = ['if', 'else', 'for', 'while', 'def', 'class', 'try', 'except']\n",
    "    keyword_distribution = {kw: len(re.findall(r'\\b' + kw + r'\\b', code)) for kw in keywords}\n",
    "    results[\"Keyword Distribution\"] = keyword_distribution\n",
    "\n",
    "    # Naming Conventions\n",
    "    pascal_case = len(re.findall(r'\\b[A-Z][a-z]*[A-Z][a-z]*\\b', code))\n",
    "    snake_case = len(re.findall(r'\\b[a-z]+(_[a-z]+)+\\b', code))\n",
    "    results[\"Naming Conventions\"] = {\"PascalCase\": pascal_case, \"snake_case\": snake_case}\n",
    "\n",
    "    # Comment Analysis\n",
    "    comments = re.findall(r'#.*', code)\n",
    "    average_comment_length = sum(len(comment) for comment in comments) / len(comments) if comments else 0\n",
    "    overly_detailed_comments = sum(1 for comment in comments if len(comment) > 40)\n",
    "    results[\"Comments\"] = {\n",
    "        \"Total Comments\": len(comments),\n",
    "        \"Average Length\": average_comment_length,\n",
    "        \"Overly Detailed Comments\": overly_detailed_comments\n",
    "    }\n",
    "\n",
    "    # Cyclomatic Complexity\n",
    "    tree = ast.parse(code)\n",
    "    complexity = 1\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, (ast.If, ast.For, ast.While, ast.Try, ast.FunctionDef)):\n",
    "            complexity += 1\n",
    "    results[\"Cyclomatic Complexity\"] = complexity\n",
    "\n",
    "    # Code Duplication Detection\n",
    "    def find_duplicate_functions(tree):\n",
    "        function_names = defaultdict(list)\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.FunctionDef):\n",
    "                function_names[node.name].append(ast.get_source_segment(code, node))\n",
    "\n",
    "        duplicates = {name: func_code for name, func_code in function_names.items() if len(func_code) > 1}\n",
    "        return duplicates\n",
    "\n",
    "    duplicates = find_duplicate_functions(tree)\n",
    "    results[\"Duplicate Functions\"] = {name: len(funcs) for name, funcs in duplicates.items()}\n",
    "\n",
    "    # Repetitive Patterns Check\n",
    "    repetitive_patterns = re.findall(r'\\b\\w+\\b', code)\n",
    "    repetitive_count = len([word for word in repetitive_patterns if repetitive_patterns.count(word) > 3])\n",
    "    results[\"Repetitive Patterns\"] = repetitive_count\n",
    "\n",
    "    # Variable & Function Naming Analysis\n",
    "    overly_descriptive_names = sum(\n",
    "        1 for name in re.findall(r'\\b[a-zA-Z_]{10,}\\b', code) if '_' in name\n",
    "    )\n",
    "    results[\"Overly Descriptive Names\"] = overly_descriptive_names\n",
    "\n",
    "    # Simple Logic and Default Values\n",
    "    default_values = len(re.findall(r'\\b=\\s*[\\'\\\"\\d\\[\\]\\{\\}\\(\\)]', code))\n",
    "    results[\"Default Values\"] = default_values\n",
    "\n",
    "    # Exception Handling\n",
    "    exception_handlers = len(re.findall(r'\\btry\\b.*?\\bexcept\\b', code, re.DOTALL))\n",
    "    results[\"Exception Handling\"] = exception_handlers\n",
    "\n",
    "    # AI Generated Probability\n",
    "    ai_score = 0\n",
    "    total_weight = 9\n",
    "\n",
    "    ai_score += (complexity < 10) * (1 / total_weight)\n",
    "    ai_score += (average_comment_length > 15) * (2 / total_weight)\n",
    "    ai_score += (pascal_case == 0) * (1 / total_weight)\n",
    "    ai_score += (snake_case > 0) * (1 / total_weight)\n",
    "    ai_score += (len(duplicates) > 0) * (0.5 / total_weight)\n",
    "    ai_score += (repetitive_count > 5) * (1 / total_weight)\n",
    "    ai_score += (overly_descriptive_names > 2) * (1 / total_weight)\n",
    "    ai_score += (default_values > 2) * (0.5 / total_weight)\n",
    "    ai_score += (exception_handlers <= 2) * (1 / total_weight)\n",
    "\n",
    "    ai_probability = ai_score * 100\n",
    "    results[\"AI Generated Probability (%)\"] = round(ai_probability, 2)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def analyze_directory(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".py\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, 'r') as file:\n",
    "                code = file.read()\n",
    "                results = analyze_code(code, filename)\n",
    "\n",
    "                print(f\"=== Analysis for {directory}/{filename} ===\")\n",
    "                # for key, value in results.items():\n",
    "                #     print(f\"{key}: {value}\")\n",
    "                print(f\"'AI Generated Probability (%): {results['AI Generated Probability (%)']}\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "\n",
    "analyze_directory('code_samples/ai')\n",
    "analyze_directory('code_samples/human')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obliczone prawdopodobieństwo przyjmuje zauważalnie wyższe wartości dla syntetycznych kodów. \n",
    "\n",
    "---\n",
    "\n",
    "Kolejnym etapem jest skupienie się na sposobie zakodowania kodu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'abc def'\n",
      "b'a\\xc4\\x85bc def'\n",
      "97\n",
      "196\n",
      "133\n",
      "Bitowa reprezentacja w UTF-8: 01100001 11000100 10000101 01100010 01100011 00100000 01100100 01100101 01100110\n",
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"=======\")\\nfor i, line in enumerate(content_string):\\n    bytes_rep = [format(ord(char), \\'08b\\') for char in line]\\n    utf_rep = [bytes(char, encoding=\\'utf-8\\') for char in line]\\n    \\n    print(f\"LINE: {i}, - {line}\")\\n    print(f\"bytes: {bytes_rep}\")\\n    print(f\"encoded: {utf_rep}\")\\n    print(\\'-\\')\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_ai = 'code_samples/ai/binary_search.py'\n",
    "with open(example_ai, 'r') as f:\n",
    "    content_string = f.readlines()\n",
    "\n",
    "\n",
    "msg = \"abc def\"\n",
    "arr = bytes(msg, 'utf-8')\n",
    "print(arr)\n",
    "\n",
    "text = \"aąbc def\"\n",
    "ta = text.encode('utf-8')\n",
    "print(ta)\n",
    "print(ta[0])\n",
    "print(ta[1])\n",
    "print(ta[2])\n",
    "\n",
    "bit_repr = ' '.join(format(byte, '08b') for byte in text.encode('utf-8'))\n",
    "print(\"Bitowa reprezentacja w UTF-8:\", bit_repr)\n",
    "\n",
    "print(ord(\" \"))\n",
    "'''\n",
    "print(\"=======\")\n",
    "for i, line in enumerate(content_string):\n",
    "    bytes_rep = [format(ord(char), '08b') for char in line]\n",
    "    utf_rep = [bytes(char, encoding='utf-8') for char in line]\n",
    "    \n",
    "    print(f\"LINE: {i}, - {line}\")\n",
    "    print(f\"bytes: {bytes_rep}\")\n",
    "    print(f\"encoded: {utf_rep}\")\n",
    "    print('-')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

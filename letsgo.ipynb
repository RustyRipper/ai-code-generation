{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Znakowanie i identyfikacja kodu wygenerowanego przez AI\n",
    "\n",
    "Temat automatycznej generacji kodu źródłowego przez Sztuczną Inteliencję (AI) jest obszerny i obejmuje różne techniki, modele oraz zastosowania. Przedmiotem naszego zainteresowania na kursie jest natomiast znalezienie sposobu na zrozumienie czy popularne generatory kodu (i ogólnego użycia) tworzą go w specyficzny dla siebie sposób, i jak tak to jaki. Chcemy odpowiedzieć na pytanie czy w dostarczonym kodzie można odnaleźć pewne statystyczne wzorce - czyli, czy AI posiada swój styl mogący go później zidentyfikować jako autora - podobnie do programistów.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naszą pierwszą czynnością było wygenerowanie kilku prostych matematycznych funkcji i algorytmów w języku Python przy użyciu ChatGPT. Już na pierwszy rzut okna dało się zauważyć pewne elementy, które mogłyby odbiegać od *normy*:\n",
    "- kod nie korzysta możliwości Pythona co do pisania zwięzłych i bardziej złożonych struktur syntaktycznych\n",
    "- przy każdej operacji pojawia się komentarz zaczynający się od wielkiej litery, a zmienne wykorzystywane mają dokładnie taką nazwę jak w komentarzu\n",
    "\n",
    "Celem jest znalezienie **statystycznego** potwierdzenia naszej intuicji, oraz znalezienie **ukrytych artefaktów** o ile istnieją - za pomocą różnych metod i narzędzie programistycznych.\n",
    "\n",
    "Zadanie detekcji, czy dany fragement kodu został napisany przez AI okazał się niezbyt dobrze opisanym w literaturze tematem, a przynajmniej takie odnieślismy wrażenie. Większość artykułów dotyczyło danych w postaci **tekstowej**. Kod oczywiście również jest zapisany w postaci tekstowej, jednak języki programowania ze względu na swoje przeznaczenie różnią się w aspektach gramatycznych i składniowych, które potrafiły być czynnikiem decydującym o decyzji czy badany tekst jest dziełem człowieka czy AI.\n",
    "Wyżej wymienione przypuszczenia przykuły też uwagę innych badaczy [1](https://arxiv.org/abs/2405.16133), którzy również zwrócili uwagę na dysproporcję w dokumentacji wykrywania wygenerowanych przez AI fragmentów kodu a tekstu i niedostępności datasetów - co było trochę oczekiwane, ponieważ dopiero od w miare niedługiego okresu, rozwiązania AI stały się użytecznym narzędziem a zarazem problemem.\n",
    "\n",
    "W swoim artykule zaprezentowali metodę wykrywania polegającą na porównaniu przepisywania przez AI kodu przygotowanego przez 1. człowieka i 2. ai. \n",
    "\n",
    "![llm rewriting](./assets/llmrewriting.png)\n",
    "\n",
    "Dzięki tej obserwacji przygotowali dataset z sztucznie wygenerowanymi funkcjami, z którego możemy skorzystać. Jednak zdecydowali się nauczyć model, a my chcemy deterministycznie znaleźć te różnice.\n",
    "\n",
    "W innym znalezionym badaniu [2] [https://ieeexplore.ieee.org/document/9674263/], badacze zdecydowali się stworzyć algorytm heurystyczny, który uwzględniał analizę programów z repozytoriów.\n",
    "\n",
    "![heurystyka](./assets/heurystyka.png)\n",
    "\n",
    "Na jego podobieństwo zbudowaliśmy własny algorytm heurystyczny, który mimo swojej prostoty i małej próbki danych potrafił wskazać na pochodzenie syntetyczne lub nie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Analysis for code_samples/ai/binary_search.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/bubble_sort.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/factorial.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/fib.py ===\n",
      "'AI Generated Probability (%): 88.89\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/is_prime.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/ai/palindrome.py ===\n",
      "'AI Generated Probability (%): 77.78\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/binary_search.py ===\n",
      "'AI Generated Probability (%): 66.67\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/bubble_sort.py ===\n",
      "'AI Generated Probability (%): 44.44\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/factorial.py ===\n",
      "'AI Generated Probability (%): 33.33\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/fib.py ===\n",
      "'AI Generated Probability (%): 44.44\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/is_prime.py ===\n",
      "'AI Generated Probability (%): 44.44\n",
      "\n",
      "\n",
      "=== Analysis for code_samples/human/palindrome.py ===\n",
      "'AI Generated Probability (%): 33.33\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def analyze_code(code, filename):\n",
    "    results = {\"Filename\": filename}\n",
    "\n",
    "    # Keyword Distribution\n",
    "    keywords = ['if', 'else', 'for', 'while', 'def', 'class', 'try', 'except']\n",
    "    keyword_distribution = {kw: len(re.findall(r'\\b' + kw + r'\\b', code)) for kw in keywords}\n",
    "    results[\"Keyword Distribution\"] = keyword_distribution\n",
    "\n",
    "    # Naming Conventions\n",
    "    pascal_case = len(re.findall(r'\\b[A-Z][a-z]*[A-Z][a-z]*\\b', code))\n",
    "    snake_case = len(re.findall(r'\\b[a-z]+(_[a-z]+)+\\b', code))\n",
    "    results[\"Naming Conventions\"] = {\"PascalCase\": pascal_case, \"snake_case\": snake_case}\n",
    " \n",
    "    # Comment Analysis\n",
    "    comments = re.findall(r'#.*', code)\n",
    "    average_comment_length = sum(len(comment) for comment in comments) / len(comments) if comments else 0\n",
    "    overly_detailed_comments = sum(1 for comment in comments if len(comment) > 40)\n",
    "    results[\"Comments\"] = {\n",
    "        \"Total Comments\": len(comments),\n",
    "        \"Average Length\": average_comment_length,\n",
    "        \"Overly Detailed Comments\": overly_detailed_comments\n",
    "    }\n",
    "\n",
    "    # Cyclomatic Complexity\n",
    "    tree = ast.parse(code)\n",
    "    complexity = 1\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, (ast.If, ast.For, ast.While, ast.Try, ast.FunctionDef)):\n",
    "            complexity += 1\n",
    "    results[\"Cyclomatic Complexity\"] = complexity\n",
    "\n",
    "    # Code Duplication Detection\n",
    "    def find_duplicate_functions(tree):\n",
    "        function_names = defaultdict(list)\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.FunctionDef):\n",
    "                function_names[node.name].append(ast.get_source_segment(code, node))\n",
    "\n",
    "        duplicates = {name: func_code for name, func_code in function_names.items() if len(func_code) > 1}\n",
    "        return duplicates\n",
    "\n",
    "    duplicates = find_duplicate_functions(tree)\n",
    "    results[\"Duplicate Functions\"] = {name: len(funcs) for name, funcs in duplicates.items()}\n",
    "\n",
    "    # Repetitive Patterns Check\n",
    "    repetitive_patterns = re.findall(r'\\b\\w+\\b', code)\n",
    "    repetitive_count = len([word for word in repetitive_patterns if repetitive_patterns.count(word) > 3])\n",
    "    results[\"Repetitive Patterns\"] = repetitive_count\n",
    "\n",
    "    # Variable & Function Naming Analysis\n",
    "    overly_descriptive_names = sum(\n",
    "        1 for name in re.findall(r'\\b[a-zA-Z_]{10,}\\b', code) if '_' in name\n",
    "    )\n",
    "    results[\"Overly Descriptive Names\"] = overly_descriptive_names\n",
    "\n",
    "    # Simple Logic and Default Values\n",
    "    default_values = len(re.findall(r'\\b=\\s*[\\'\\\"\\d\\[\\]\\{\\}\\(\\)]', code))\n",
    "    results[\"Default Values\"] = default_values\n",
    "\n",
    "    # Exception Handling\n",
    "    exception_handlers = len(re.findall(r'\\btry\\b.*?\\bexcept\\b', code, re.DOTALL))\n",
    "    results[\"Exception Handling\"] = exception_handlers\n",
    "\n",
    "    # AI Generated Probability\n",
    "    ai_score = 0\n",
    "    total_weight = 9\n",
    "\n",
    "    ai_score += (complexity < 10) * (1 / total_weight)\n",
    "    ai_score += (average_comment_length > 15) * (2 / total_weight)\n",
    "    ai_score += (pascal_case == 0) * (1 / total_weight)\n",
    "    ai_score += (snake_case > 0) * (1 / total_weight)\n",
    "    ai_score += (len(duplicates) > 0) * (0.5 / total_weight)\n",
    "    ai_score += (repetitive_count > 5) * (1 / total_weight)\n",
    "    ai_score += (overly_descriptive_names > 2) * (1 / total_weight)\n",
    "    ai_score += (default_values > 2) * (0.5 / total_weight)\n",
    "    ai_score += (exception_handlers <= 2) * (1 / total_weight)\n",
    "\n",
    "    ai_probability = ai_score * 100\n",
    "    results[\"AI Generated Probability (%)\"] = round(ai_probability, 2)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def analyze_directory(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".py\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, 'r') as file:\n",
    "                code = file.read()\n",
    "                results = analyze_code(code, filename)\n",
    "\n",
    "                print(f\"=== Analysis for {directory}/{filename} ===\")\n",
    "                # for key, value in results.items():\n",
    "                #     print(f\"{key}: {value}\")\n",
    "                print(f\"'AI Generated Probability (%): {results['AI Generated Probability (%)']}\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "\n",
    "analyze_directory('code_samples/ai')\n",
    "analyze_directory('code_samples/human')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obliczone prawdopodobieństwo przyjmuje zauważalnie wyższe wartości dla syntetycznych kodów. \n",
    "\n",
    "---\n",
    "\n",
    "Kolejnym etapem jest skupienie się na sposobie zakodowania kodu - spróbowaliśmy zawrzeć wzorzec do kodu. Mianowicie, dla wybranego tekstu kodu, w co drugiej linijce dodajemy spację lub tabulator do końca linii. Te znaki będą nam mówić o wartości bitu. \n",
    "- spacja = 0\n",
    "- tab = 1\n",
    "\n",
    "Znaki są ustawiane w taki sposób, aby odczytując kod z góry do dołu tworzyły nam się bloki bajtowe, które są kodem litery naszego hasła.\n",
    "Limitacją na razie jest długość kodu i długość hasła, ale to będzie ulepszane. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_watermark(code, watermark=\"LABORATORIA\"):\n",
    "    watermark_binary = ''.join(\n",
    "        ['\\t' if bit == '1' else ' ' for bit in ''.join(format(ord(c), '08b') for c in watermark)])\n",
    "    print(\"Watermark binary:\" + watermark_binary)\n",
    "    print('Dlugosc watermarku: ' + str(len(watermark)))\n",
    "    print('Dlugosc binarna watermarku: ' + str(len(watermark_binary)))\n",
    "    lines = code.splitlines()\n",
    "\n",
    "    for i in range(1, len(lines), 2):\n",
    "        if i // 2 < len(watermark_binary):\n",
    "            lines[i] += watermark_binary[i // 2]\n",
    "\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "\n",
    "def extract_watermark(code):\n",
    "    lines = code.splitlines()\n",
    "\n",
    "    binary_pattern = []\n",
    "    for i in range(1, len(lines), 2):\n",
    "        if lines[i].endswith(\" \") or lines[i].endswith(\"\\t\"):\n",
    "            last_char = lines[i][-1]\n",
    "            binary_pattern.append('1' if last_char == '\\t' else '0')\n",
    "\n",
    "    watermark_text = ''\n",
    "    for i in range(0, len(binary_pattern), 8):\n",
    "        byte = ''.join(binary_pattern[i:i + 8])\n",
    "        if len(byte) == 8:\n",
    "            watermark_text += chr(int(byte, 2))\n",
    "\n",
    "    return watermark_text if watermark_text else \"Brak znaku wodnego\"\n",
    "\n",
    "\n",
    "with open(\"../init-code/init.py\", \"r\") as f:\n",
    "    code_example = f.read()\n",
    "\n",
    "watermarked_code = add_watermark(code_example)\n",
    "print(\"Watermarkowany kod:\" + watermarked_code)\n",
    "\n",
    "detected_watermark = extract_watermark(watermarked_code)\n",
    "print(\"Odczytany przykladowy kod:\", code_example)\n",
    "\n",
    "detected_watermark_2 = extract_watermark(watermarked_code)\n",
    "print(\"Odczytany watermark:\", detected_watermark_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "''' NA RAZIE NIE\n",
    "example_ai = 'code_samples/ai/binary_search.py'\n",
    "with open(example_ai, 'rb') as f:\n",
    "    content_string = f.readlines()\n",
    "\n",
    "print(content_string[0][0])\n",
    "print(content_string[0])\n",
    "print(format(content_string[0][0], '08b'))\n",
    "print('--------------------------')\n",
    "\n",
    "latin_chars_and_nrs = [(65, 122), (48, 57)]\n",
    "\n",
    "def check_for_unusual_chars(file_bytelines: list):\n",
    "    unusual_chars = []\n",
    "    for i, line in enumerate(file_bytelines):\n",
    "        print(\"FILE LINE IN BYTES:\", line)\n",
    "        for char_nr in line:\n",
    "            if not any(usual[0] <= char_nr <= usual[1] for usual in latin_chars_and_nrs):\n",
    "                unusual_chars.append((i, char_nr))\n",
    "    return unusual_chars\n",
    "\n",
    "\n",
    "unusual_chars = check_for_unusual_chars(content_string)\n",
    "print(\"UNUSUAL CHARACTERS: \", unusual_chars)\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
